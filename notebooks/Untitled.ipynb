{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN classifier for arming the edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Add, Activation, Concatenate, Flatten\n",
    "from tensorflow.keras.layers import Cropping2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop white space out of all images if not already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19500\n"
     ]
    }
   ],
   "source": [
    "raw_images = '/lambda_stor/data/rjackson/lidar_pngs/5min/**/*.png'\n",
    "raw_img_list = glob(raw_images, recursive=True)\n",
    "print(len(raw_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in raw_img_list:\n",
    "    yourImage = Image.open(image_file)\n",
    "    yourImage.crop((130, 40, 1320, 410)).save(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment training images for cloudy by doing a left-right flip, same for rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2239\n"
     ]
    }
   ],
   "source": [
    "cloudy_data_path = '/lambda_stor/data/rjackson/lidar_pngs/5min/training/rain/*.png'\n",
    "cloud_images = glob(cloudy_data_path)\n",
    "print(len(cloud_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/rjackson/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/homes/rjackson/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2239/100\n",
      "2239/200\n",
      "2239/300\n",
      "2239/400\n",
      "2239/500\n",
      "2239/600\n",
      "2239/700\n",
      "2239/800\n",
      "2239/900\n",
      "2239/1000\n",
      "2239/1100\n",
      "2239/1200\n",
      "2239/1300\n",
      "2239/1400\n",
      "2239/1500\n",
      "2239/1600\n",
      "2239/1700\n",
      "2239/1800\n",
      "2239/1900\n",
      "2239/2000\n",
      "2239/2100\n",
      "2239/2200\n"
     ]
    }
   ],
   "source": [
    "train_datagen_flip = ImageDataGenerator(rescale=1/255., featurewise_std_normalization=True, featurewise_center=True,\n",
    "                                   samplewise_center=True, horizontal_flip=True)\n",
    "j = 0\n",
    "for image in cloud_images:\n",
    "    img = load_img(image)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape) \n",
    "    i = 0\n",
    "    for batch in train_datagen_flip.flow(x, batch_size=1,\n",
    "                             save_to_dir='/lambda_stor/data/rjackson/lidar_pngs/5min/training/rain/',\n",
    "                                         save_prefix='rain_flip', save_format='png'):\n",
    "        i += 1\n",
    "        if i > 1:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "    j += 1\n",
    "    if j % 100 == 0:\n",
    "        print('%d/%d' % (len(cloud_images), j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=mpimg.imread('/lambda_stor/data/rjackson/lidar_pngs/5min/training/cloud/cloud_flip_0_3804.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "# (150, 50), (1300, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255., featurewise_std_normalization=True, featurewise_center=True,\n",
    "                                   samplewise_std_normalization=True,\n",
    "                                   samplewise_center=True)\n",
    "train_datagen_flip = ImageDataGenerator(samplewise_std_normalization=True, \n",
    "                                   samplewise_center=True, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19764 images belonging to 3 classes.\n",
      "Found 2841 images belonging to 3 classes.\n",
      "Found 19764 images belonging to 3 classes.\n",
      "Found 2841 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/training',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloud', 'rain'],\n",
    "                                                    target_size=(256, 128), shuffle=True, batch_size=16)\n",
    "valid_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/validation',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloud', 'rain'],\n",
    "                                                    target_size=(256, 128), shuffle=True, batch_size=16)\n",
    "train_generator_flip = train_datagen_flip.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/training',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloud', 'rain'],\n",
    "                                                    target_size=(256, 128))\n",
    "valid_generator_flip = train_datagen_flip.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/validation',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloud', 'rain'],\n",
    "                                                    target_size=(256, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net_layer(inp, skip=False, num_channels=2, batch_norm=True,\n",
    "                   activate=True):\n",
    "    x = Conv2D(num_channels, kernel_size=(3, 3), kernel_initializer='he_normal')(inp)\n",
    "    if batch_norm:\n",
    "        x = Dropout(0.2)(x)\n",
    "    if activate:\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "    return x\n",
    "\n",
    "def conv_net_layer_up(inp, skip=False, num_channels=2, batch_norm=True,\n",
    "                   activate=True):\n",
    "    x = Conv2D(num_channels, kernel_size=(3, 3), kernel_initializer='he_normal')(inp)\n",
    "    if batch_norm:\n",
    "        x = Dropout(0.2)(x)\n",
    "    if activate:\n",
    "        x = Activation('relu')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "    return x\n",
    "\n",
    "def conv_net_classifier(velocity=False):\n",
    "    ref_inp = Input(shape=(256, 128, 3), name='snr')\n",
    "      \n",
    "    layer2 = conv_net_layer(ref_inp, num_channels=32, batch_norm=True,\n",
    "             activate=True)\n",
    "    \n",
    "    layer2 = conv_net_layer(layer2, num_channels=64, batch_norm=True,\n",
    "             activate=True)\n",
    "    \n",
    "    ref_out = conv_net_layer(layer2, num_channels=32, batch_norm=True,\n",
    "             activate=True)\n",
    "    ref_out = conv_net_layer(layer2, num_channels=1)\n",
    "\n",
    "    #ref_out = conv_net_layer(layer2, num_channels=1, batch_norm=True, activate=False)\n",
    "    #ref_skip = conv_net_layer(ref, num_channels=1, batch_norm=True, activate=False)\n",
    "    #ref_skip = Activation('relu')(ref_skip)\n",
    "    #ref_out = Add()([ref_out, ref_skip])\n",
    "    #ref_out = Activation('relu')(ref_out)\n",
    "    if velocity:   \n",
    "        x = Concatenate()([ref_out, vel_out])\n",
    "    else:\n",
    "        x = ref_out \n",
    "    \n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = Flatten()(x)\n",
    "    #x = AveragePooling2D()(x)\n",
    "    outputs = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(3, name='targets',\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(outputs)\n",
    "\n",
    "    #x = Dense(2, activation='relu')(x)\n",
    "    #x = Dense(3, activation='softmax', name='label')(x)\n",
    "    if velocity:\n",
    "        return Model(inputs=[ref_in, vel_in], outputs=outputs)\n",
    "    else:\n",
    "        return Model(ref_inp, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "snr (InputLayer)             [(None, 256, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 254, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 254, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 254, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 63, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 61, 64)       18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 125, 61, 64)       0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 125, 61, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 60, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 420)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               53888     \n",
      "_________________________________________________________________\n",
      "targets (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 74,244\n",
      "Trainable params: 74,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = conv_net_classifier()\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/rjackson/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/homes/rjackson/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_1/conv2d/Conv2D (defined at <ipython-input-6-db824821ee93>:4) ]] [Op:__inference_train_function_1094]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-db824821ee93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/homes/rjackson/arming_the_edge/models/classifier-%dframes-{epoch:03d}.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             verbose=1)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_1/conv2d/Conv2D (defined at <ipython-input-6-db824821ee93>:4) ]] [Op:__inference_train_function_1094]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "            filepath=('/homes/rjackson/arming_the_edge/models/classifier-%dframes-{epoch:03d}.hdf5'),\n",
    "            verbose=1)\n",
    "model.fit(train_generator, validation_data=valid_generator, epochs=150, callbacks=[checkpointer], initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = model.predict(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.argmax(labels_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          ...,\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761]],\n",
       " \n",
       "         [[0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          ...,\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761]],\n",
       " \n",
       "         [[0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          ...,\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          ...,\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761]],\n",
       " \n",
       "         [[0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          ...,\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761]],\n",
       " \n",
       "         [[0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          ...,\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761],\n",
       "          [0.01083761, 0.01083761, 0.01083761]]],\n",
       " \n",
       " \n",
       "        [[[0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          ...,\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479]],\n",
       " \n",
       "         [[0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          ...,\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479]],\n",
       " \n",
       "         [[0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          ...,\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          ...,\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479]],\n",
       " \n",
       "         [[0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          ...,\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479]],\n",
       " \n",
       "         [[0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          ...,\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479],\n",
       "          [0.00954479, 0.00954479, 0.00954479]]],\n",
       " \n",
       " \n",
       "        [[[0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          ...,\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025]],\n",
       " \n",
       "         [[0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          ...,\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025]],\n",
       " \n",
       "         [[0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          ...,\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          ...,\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025]],\n",
       " \n",
       "         [[0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          ...,\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025]],\n",
       " \n",
       "         [[0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          ...,\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025],\n",
       "          [0.01129025, 0.01129025, 0.01129025]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          ...,\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736]],\n",
       " \n",
       "         [[0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          ...,\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736]],\n",
       " \n",
       "         [[0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          ...,\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          ...,\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736]],\n",
       " \n",
       "         [[0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          ...,\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736]],\n",
       " \n",
       "         [[0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          ...,\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736],\n",
       "          [0.01082736, 0.01082736, 0.01082736]]],\n",
       " \n",
       " \n",
       "        [[[0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          ...,\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107]],\n",
       " \n",
       "         [[0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          ...,\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107]],\n",
       " \n",
       "         [[0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          ...,\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          ...,\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107]],\n",
       " \n",
       "         [[0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          ...,\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107]],\n",
       " \n",
       "         [[0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          ...,\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107],\n",
       "          [0.01093107, 0.01093107, 0.01093107]]],\n",
       " \n",
       " \n",
       "        [[[0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          ...,\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ]],\n",
       " \n",
       "         [[0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          ...,\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ]],\n",
       " \n",
       "         [[0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          ...,\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          ...,\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ]],\n",
       " \n",
       "         [[0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          ...,\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ]],\n",
       " \n",
       "         [[0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          ...,\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ],\n",
       "          [0.0140925 , 0.0140925 , 0.0140925 ]]]], dtype=float32),\n",
       " array([[1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19764 images belonging to 3 classes.\n",
      "Found 2841 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/training',\n",
    "                                                    class_mode='input', target_size=(254, 126), shuffle=True,\n",
    "                                                    batch_size=16)\n",
    "valid_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/validation',\n",
    "                                                    class_mode='input', \n",
    "                                                    target_size=(254, 126), shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net_encoder():\n",
    "    ref_inp = Input(shape=(254, 126, 3), name='snr')\n",
    "      \n",
    "    x = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', activation='relu')(ref_inp)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', activation='relu')(ref_inp)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    ref_out = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', activation='relu')(x)\n",
    "    ref_out = MaxPooling2D((2,2))(ref_out)\n",
    "    ref_out = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', activation='relu')(ref_out)\n",
    "    ref_out = MaxPooling2D((2,2))(ref_out)\n",
    "    \n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = Flatten()(ref_out)\n",
    "    #x = AveragePooling2D()(x)\n",
    "    outputs = Dense(10, activation='relu')(x)\n",
    "    \n",
    "    dense_1 = Dense(30*14*32, activation='relu')(outputs)\n",
    "    dense_1 = Reshape((30,14,32))(dense_1)\n",
    "    inp = UpSampling2D((2,2))(dense_1)\n",
    "    x = Conv2DTranspose(32, kernel_size=(3, 3), kernel_initializer='he_normal', activation='relu')(inp)\n",
    "    x = UpSampling2D((2,2))(dense_1)\n",
    "    ref_out = Conv2DTranspose(32, kernel_size=(3, 3), kernel_initializer='he_normal', activation='relu')(x)\n",
    "    ref_out = UpSampling2D((2,2))(ref_out)\n",
    "    ref_out = Conv2DTranspose(32, kernel_size=(3, 3), kernel_initializer='he_normal', activation='relu')(x)\n",
    "    ref_out = UpSampling2D((2,2))(ref_out)\n",
    "    ref_out = Conv2DTranspose(32, kernel_size=(3, 3), kernel_initializer='he_normal', activation='relu')(ref_out)\n",
    "    ref_out = UpSampling2D((2,2))(ref_out)\n",
    "    ref_out = Conv2DTranspose(3, kernel_size=(3, 3), kernel_initializer='he_normal', activation='relu')(ref_out)    \n",
    "    return Model(ref_inp, ref_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = conv_net_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "snr (InputLayer)             [(None, 254, 126, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 252, 124, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 126, 62, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 124, 60, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 62, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 60, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 30, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 13440)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                134410    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 13440)             147840    \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 30, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling (None, 60, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DT (None, 62, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling (None, 124, 60, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_24 (Conv2DT (None, 126, 62, 32)       9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_25 (UpSampling (None, 252, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_25 (Conv2DT (None, 254, 126, 3)       867       \n",
      "=================================================================\n",
      "Total params: 321,005\n",
      "Trainable params: 321,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/rjackson/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-68427b64a682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0marray_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0marray_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marray_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "array_list = []\n",
    "for x in train_generator:\n",
    "    if array_list == []:\n",
    "        array_list = x\n",
    "    else:\n",
    "        array_list = np.concatenate([array_list, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_list = []\n",
    "for x in train_generator:\n",
    "    if array_list == []:\n",
    "        array_list = x\n",
    "    else:\n",
    "        array_list = np.concatenate([array_list, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "3 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_11/conv2d_23/Relu (defined at <ipython-input-24-837b435f56f6>:5) ]]\n\t [[GroupCrossDeviceControlEdges_0/Adam/Adam/Const/_113]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_11/conv2d_23/Relu (defined at <ipython-input-24-837b435f56f6>:5) ]]\n\t [[gradient_tape/functional_11/conv2d_transpose_23/conv2d_transpose/Conv2DBackpropFilter/_90]]\n  (2) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_11/conv2d_23/Relu (defined at <ipython-input-24-837b435f56f6>:5) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_4392]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ece2279746d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/homes/rjackson/arming_the_edge/models/encoder-%dframes-{epoch:03d}.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   verbose=1)\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 3 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_11/conv2d_23/Relu (defined at <ipython-input-24-837b435f56f6>:5) ]]\n\t [[GroupCrossDeviceControlEdges_0/Adam/Adam/Const/_113]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_11/conv2d_23/Relu (defined at <ipython-input-24-837b435f56f6>:5) ]]\n\t [[gradient_tape/functional_11/conv2d_transpose_23/conv2d_transpose/Conv2DBackpropFilter/_90]]\n  (2) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_11/conv2d_23/Relu (defined at <ipython-input-24-837b435f56f6>:5) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_4392]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:2'):\n",
    "    checkpointer = ModelCheckpoint(\n",
    "                  filepath=('/homes/rjackson/arming_the_edge/models/encoder-%dframes-{epoch:03d}.hdf5'),\n",
    "                  verbose=1)\n",
    "    autoencoder.fit(train_generator, validation_data=valid_generator, epochs=150, callbacks=[checkpointer], initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n",
      "(16, 254, 126, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e816a1458388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rgb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'color_mode must be \"grayscale\", \"rgb\", or \"rgba\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \"\"\"\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in train_generator:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_env] *",
   "language": "python",
   "name": "conda-env-tensorflow_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
