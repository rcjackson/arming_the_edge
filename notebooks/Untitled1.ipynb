{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN classifier for arming the edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjackson/.conda/envs/pydda_env/lib/python3.9/site-packages/IPython/core/magics/pylab.py:162: UserWarning: pylab import has clobbered these variables: ['shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from keras_unet.models import custom_unet\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Add, Activation, Concatenate, Flatten\n",
    "from tensorflow.keras.layers import Cropping2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Reshape\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "  \n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop white space out of all images if not already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22605\n"
     ]
    }
   ],
   "source": [
    "raw_images = '/lambda_stor/data/rjackson/lidar_pngs/5min/**/*.png'\n",
    "raw_img_list = glob(raw_images, recursive=True)\n",
    "print(len(raw_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in raw_img_list:\n",
    "    yourImage = Image.open(image_file)\n",
    "    yourImage.crop((130, 40, 1320, 410)).save(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment training images for cloudy by doing a left-right flip, same for rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606\n"
     ]
    }
   ],
   "source": [
    "cla = 'rain'\n",
    "num_replications = 15\n",
    "cloudy_data_path = '/lcrc/group/earthscience/rjackson/lidar_pngs/5min_snr/training/%s/*.png' % cla\n",
    "cloud_images = glob(cloudy_data_path)\n",
    "print(len(cloud_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/606\n",
      "200/606\n",
      "300/606\n",
      "400/606\n",
      "500/606\n",
      "600/606\n"
     ]
    }
   ],
   "source": [
    "train_datagen_flip = ImageDataGenerator(rescale=1/255., \n",
    "                                        horizontal_flip=True, \n",
    "                                        width_shift_range=[-5, 5])\n",
    "j = 0\n",
    "for image in cloud_images:\n",
    "    img = load_img(image)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape) \n",
    "\n",
    "    i = 0\n",
    "    for batch in train_datagen_flip.flow(x, batch_size=1,\n",
    "                                        save_to_dir='/lcrc/group/earthscience/rjackson/lidar_pngs/augmented/%s/' % cla,\n",
    "                                        save_prefix=str(j) + str(i), save_format='png'):\n",
    "        i += 1\n",
    "        if i >= num_replications:\n",
    "            break\n",
    "    \n",
    "    j += 1\n",
    "    if j % 100 == 0:\n",
    "        print('%d/%d' % (j, len(cloud_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_flip = ImageDataGenerator(rescale=1/255., \n",
    "                                        horizontal_flip=True, \n",
    "                                        brightness_range=[0.95, 1.05], width_shift_range=[-5, 5])\n",
    "j = 0\n",
    "fig, ax = plt.subplots(6, 6, figsize=(15, 20))\n",
    "image = cloud_images[0]\n",
    "img = load_img(image)\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape) \n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for batch in train_datagen_flip.flow(x, batch_size=1):\n",
    "    ax[i, j].imshow(batch[0])\n",
    "    i = i + 1\n",
    "    if i >= 6:\n",
    "        j = j + 1\n",
    "        i = 0\n",
    "    if j >= 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 566, 4)\n"
     ]
    }
   ],
   "source": [
    "img=mpimg.imread('/lambda_stor/data/rjackson/lidar_pngs/5min/training/cloudy/sgpdlacfC1.a1.20170924.220114.moments11.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "print(img.shape)\n",
    "# (150, 50), (1300, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "train_generator = train_datagen.flow_from_directory(directory='/lcrc/group/earthscience/rjackson/lidar_pngs/5min/training',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloudy', 'rain'],\n",
    "                                                    target_size=(256, 128), shuffle=True, batch_size=16)\n",
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_datagen_flip = ImageDataGenerator(rescale=1/255., horizontal_flip=True, width_shift_range=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13707 images belonging to 3 classes.\n",
      "Found 6617 images belonging to 3 classes.\n",
      "Found 29623 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory='/lcrc/group/earthscience/rjackson/lidar_pngs/5min_snr/training',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloudy', 'rain'],\n",
    "                                                    target_size=(256, 192), shuffle=True, batch_size=32)\n",
    "valid_generator = train_datagen.flow_from_directory(directory='/lcrc/group/earthscience/rjackson/lidar_pngs/5min_snr/validation',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloudy', 'rain'],\n",
    "                                                    target_size=(256, 192), shuffle=True, batch_size=32)\n",
    "train_generator_flip = train_datagen.flow_from_directory(directory='/lcrc/group/earthscience/rjackson/lidar_pngs/augmented',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloudy', 'rain'],\n",
    "                                                    target_size=(256, 192), batch_size=32)\n",
    "#valid_generator_flip = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/augmented/',\n",
    "#                                                    class_mode='categorical', classes=['clear', 'cloudy', 'rain'],\n",
    "#                                                    target_size=(512, 128), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(IMG_HEIGHT=256, IMG_WIDTH=128):\n",
    "    restnet = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3))\n",
    "    restnet.summary()\n",
    "    output = restnet.layers[-1].output\n",
    "    output = Flatten()(output)\n",
    "    restnet = Model(restnet.input,output)\n",
    "    for layer in restnet.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(restnet)\n",
    "    model.add(Dense(512, activation='relu', bias_regularizer=l2(0.01)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu', bias_regularizer=l2(0.01)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu', bias_regularizer=l2(0.01)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(3, name='targets',\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal', bias_regularizer=l2(0.01)))\n",
    "    return model\n",
    "\n",
    "def vgg(IMG_HEIGHT=256, IMG_WIDTH=128):\n",
    "    restnet = VGG19(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3))\n",
    "    restnet.summary()\n",
    "    output = restnet.layers[-1].output\n",
    "    output = Flatten()(output)\n",
    "    restnet = Model(restnet.input,output)\n",
    "    #for layer in restnet.layers[:-4]:\n",
    "    #    layer.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(restnet)\n",
    "    model.add(restnet)\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(3, name='targets',\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=l2(0.01)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net_layer(inp, skip=False, num_channels=2, batch_norm=True,\n",
    "                   activate=True, add_layer=None):\n",
    "    x = Conv2D(num_channels, kernel_size=(2, 2), kernel_initializer='he_normal', padding='same',\n",
    "              kernel_regularizer=l2(0.01))(inp)\n",
    "    x = Conv2D(num_channels, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same',\n",
    "              kernel_regularizer=l2(0.01))(x)\n",
    "    if batch_norm:\n",
    "        x = Dropout(0.3)(x)\n",
    "    if activate:\n",
    "        if add_layer is True:\n",
    "            x = Add()([x, inp])\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "    return x\n",
    "\n",
    "def conv_net_layer_up(inp, skip=False, num_channels=2, batch_norm=True,\n",
    "                      activate=True, add_layer=None):\n",
    "    x = Conv2D(1, kernel_size=(3, 3), kernel_initializer='he_normal')(inp)\n",
    "    x = Conv2D(num_channels, kernel_size=(3, 3), kernel_initializer='he_normal')(x)\n",
    "    x = Conv2D(3, kernel_size=(3, 3), kernel_initializer='he_normal')(x)\n",
    "    if batch_norm:\n",
    "        x = Dropout(0.3)(x)\n",
    "    if activate:\n",
    "        if add_layer is not None:\n",
    "            x = Add()([x, inp])\n",
    "        x = Activation('relu')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "    return x\n",
    "\n",
    "def conv_net_classifier(velocity=False):\n",
    "    ref_inp = Input(shape=(256, 128, 3), name='snr')\n",
    "          \n",
    "    layer2 = conv_net_layer(ref_inp, num_channels=16, batch_norm=True,\n",
    "             activate=True, add_layer=False)\n",
    "    layer2 = conv_net_layer(layer2, num_channels=16, batch_norm=True,\n",
    "             activate=True, add_layer=False)\n",
    "    layer2 = conv_net_layer(layer2, num_channels=16, batch_norm=True,\n",
    "             activate=True, add_layer=False)\n",
    "    layer2 = conv_net_layer(layer2, num_channels=16, batch_norm=True,\n",
    "             activate=True, add_layer=False)\n",
    "    layer2 = conv_net_layer(layer2, num_channels=16, batch_norm=True,\n",
    "             activate=True, add_layer=False)\n",
    "    ref_out = conv_net_layer(layer2, num_channels=16, add_layer=False, batch_norm=True, activate=False)\n",
    "    #ref_skip = Activation('relu')(ref_skip)\n",
    "    #ref_out = Add()([ref_out, ref_skip])\n",
    "    #ref_out = Activation('relu')(ref_out)\n",
    "    if velocity:   \n",
    "        x = Concatenate()([ref_out, vel_out])\n",
    "    else:\n",
    "        x = ref_out \n",
    "    \n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = Flatten()(x)\n",
    "    #x = AveragePooling2D()(x)\n",
    "    outputs = Dense(512, activation='relu',)(x)\n",
    "    outputs = Dense(512, activation='relu',)(outputs)\n",
    "    outputs = Dense(512, activation='relu',)(outputs)\n",
    "    outputs = Dense(512, activation='relu',)(outputs)\n",
    "    outputs = Dense(3, name='targets',\n",
    "                    activation='softmax', activity_regularizer=l1(0.01),\n",
    "                    )(outputs)\n",
    "\n",
    "    #x = Dense(2, activation='relu')(x)\n",
    "    #x = Dense(3, activation='softmax', name='label')(x)\n",
    "    if velocity:\n",
    "        return Model(inputs=[ref_in, vel_in], outputs=outputs)\n",
    "    else:\n",
    "        return Model(ref_inp, outputs)\n",
    "\n",
    "def combine_generator(gen1, gen2):\n",
    "    while True:\n",
    "        yield(next(gen1), next(gen2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 256, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 64, 64)       0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 64, 128)      73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 64, 128)      147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 64, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 32, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 8, 512)        0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 8, 512)        2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 8, 512)        2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 8, 512)        2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 16, 8, 512)        2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 256, 128, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256, 128, 3), dtype=tf.float32, name='input_20'), name='input_20', description=\"created by layer 'input_20'\"), but it was called on an input with incompatible shape (None, 16384).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"model_19\" (type Functional).\n\nInput 0 of layer \"block1_conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 16384)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 16384), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mvgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m lr_schedule \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mschedules\u001b[38;5;241m.\u001b[39mExponentialDecay(\n\u001b[1;32m      3\u001b[0m     initial_learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m,\n\u001b[1;32m      4\u001b[0m     decay_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m,\n\u001b[1;32m      5\u001b[0m     decay_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36mvgg\u001b[0;34m(IMG_HEIGHT, IMG_WIDTH)\u001b[0m\n\u001b[1;32m     30\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39madd(restnet)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestnet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m512\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_regularizer\u001b[38;5;241m=\u001b[39ml2(\u001b[38;5;241m0.01\u001b[39m)))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#model.add(Dropout(0.3))\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/keras/engine/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    226\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    228\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    230\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    231\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"model_19\" (type Functional).\n\nInput 0 of layer \"block1_conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 16384)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 16384), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "model = vgg()\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.9)\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.0953 - accuracy: 0.3761\n",
      "Epoch 00001: saving model to /homes/rjackson/arming_the_edge/models/vgg-combined-1layer-001.hdf5\n",
      "755/755 [==============================] - 43s 57ms/step - loss: 1.0953 - accuracy: 0.3761 - val_loss: 1.0662 - val_accuracy: 0.2785\n",
      "Epoch 2/2000\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.0953 - accuracy: 0.3761\n",
      "Epoch 00002: saving model to /homes/rjackson/arming_the_edge/models/vgg-combined-1layer-002.hdf5\n",
      "755/755 [==============================] - 44s 59ms/step - loss: 1.0953 - accuracy: 0.3761 - val_loss: 1.1090 - val_accuracy: 0.2785\n",
      "Epoch 3/2000\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.0951 - accuracy: 0.3748\n",
      "Epoch 00003: saving model to /homes/rjackson/arming_the_edge/models/vgg-combined-1layer-003.hdf5\n",
      "755/755 [==============================] - 43s 57ms/step - loss: 1.0951 - accuracy: 0.3748 - val_loss: 1.0868 - val_accuracy: 0.2785\n",
      "Epoch 4/2000\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.0953 - accuracy: 0.3761\n",
      "Epoch 00004: saving model to /homes/rjackson/arming_the_edge/models/vgg-combined-1layer-004.hdf5\n",
      "755/755 [==============================] - 43s 57ms/step - loss: 1.0953 - accuracy: 0.3761 - val_loss: 1.0792 - val_accuracy: 0.2785\n",
      "Epoch 5/2000\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.0952 - accuracy: 0.3761\n",
      "Epoch 00005: saving model to /homes/rjackson/arming_the_edge/models/vgg-combined-1layer-005.hdf5\n",
      "755/755 [==============================] - 44s 58ms/step - loss: 1.0952 - accuracy: 0.3761 - val_loss: 1.1021 - val_accuracy: 0.2785\n",
      "Epoch 6/2000\n",
      "754/755 [============================>.] - ETA: 0s - loss: 1.0950 - accuracy: 0.3751\n",
      "Epoch 00006: saving model to /homes/rjackson/arming_the_edge/models/vgg-combined-1layer-006.hdf5\n",
      "755/755 [==============================] - 44s 58ms/step - loss: 1.0950 - accuracy: 0.3750 - val_loss: 1.0931 - val_accuracy: 0.2785\n",
      "Epoch 7/2000\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.0952 - accuracy: 0.3761\n",
      "Epoch 00007: saving model to /homes/rjackson/arming_the_edge/models/vgg-combined-1layer-007.hdf5\n",
      "755/755 [==============================] - 44s 58ms/step - loss: 1.0952 - accuracy: 0.3761 - val_loss: 1.1327 - val_accuracy: 0.2785\n",
      "Epoch 8/2000\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.0952 - accuracy: 0.3761\n",
      "Epoch 00008: saving model to /homes/rjackson/arming_the_edge/models/vgg-combined-1layer-008.hdf5\n",
      "755/755 [==============================] - 44s 58ms/step - loss: 1.0952 - accuracy: 0.3761 - val_loss: 1.1049 - val_accuracy: 0.2785\n",
      "Epoch 9/2000\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.0949 - accuracy: 0.3761\n",
      "Epoch 00009: saving model to /homes/rjackson/arming_the_edge/models/vgg-combined-1layer-009.hdf5\n",
      "755/755 [==============================] - 44s 58ms/step - loss: 1.0949 - accuracy: 0.3761 - val_loss: 1.1135 - val_accuracy: 0.2785\n",
      "Epoch 10/2000\n",
      "394/755 [==============>...............] - ETA: 18s - loss: 1.0950 - accuracy: 0.3761"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m      5\u001b[0m                filepath\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/homes/rjackson/arming_the_edge/models/vgg-combined-1layer-\u001b[39m\u001b[38;5;132;01m{epoch:03d}\u001b[39;00m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator_flip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class_weight = {0: 1.,\n",
    "                1: 2.5,\n",
    "                2: 15.}\n",
    "checkpointer = ModelCheckpoint(\n",
    "               filepath=('/homes/rjackson/arming_the_edge/models/vgg-combined-1layer-{epoch:03d}.hdf5'),\n",
    "               verbose=1)\n",
    "early_stopping = EarlyStopping(restore_best_weights=True, patience=100, monitor=\"val_loss\", mode=\"max\")\n",
    "history = model.fit(train_generator_flip, validation_data=valid_generator, epochs=2000,\n",
    "          callbacks=[checkpointer, early_stopping], initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = model.predict(valid_generator)\n",
    "labels_train = model.predict(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../models/resnet50-040.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='training')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.75, 1])\n",
    "plt.legend()\n",
    "plt.title('Vgg19 3 layers tuned')\n",
    "plt.savefig('Vgg193layers.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layerwise relevance propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fad6000c950>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a61d1d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fafd452b5d0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fad5a583410>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fad5a583550>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fad60faac90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad6118d2d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad60b671d0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fad5a58a950>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fad5a58aa90>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fad5a58abd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a58d190>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a58d8d0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fad5a58dfd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fad5a583f10>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fad5a5ffcd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a588750>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a588dd0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fad5a5934d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fad5a593610>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fad5a593790>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a593d50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a59e450>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fad5a59ebd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fad5a59ed10>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fad5a59ed90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a5a0450>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a5a0ad0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fad60faaa10>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x7fad5a5a54d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fad5a5a5690>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fad5a5a5b10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fad5a5a5d90>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fad5a53e190>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fad5a53e3d0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fad5a53e810>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fad5a53ea50>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for i in range(10):\n",
    "    x, y = valid_generator.next()\n",
    "    xs.append(tf.convert_to_tensor(x))\n",
    "    ys.append(tf.convert_to_tensor(y))\n",
    "#x = np.stack(x)\n",
    "#y = np.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.activations.softmax(x, axis=-1)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-1].activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def lrp(model, x, y):\n",
    "    Rn = model.layers[-1].activation(y)\n",
    "    Rnp1 = 0\n",
    "    # Compute activations\n",
    "    A = []\n",
    "    xi = x\n",
    "    for L in model.layers:\n",
    "        print(L)\n",
    "        xi = L.apply(xi)\n",
    "        if isinstance(L, tf.keras.layers.InputLayer):\n",
    "            A.append(xi)\n",
    "        else:\n",
    "            A.append(L.activation(xi))\n",
    "    \n",
    "    i = len(model.layers)\n",
    "    for L in model.layers[:1:-1]:\n",
    "        z = np.eps + A[i].dot(L.weights)\n",
    "        s = Rn / z\n",
    "        c = s.dot(L.weights)\n",
    "        Rn = A[i - 1] * c\n",
    "        i = i - 1\n",
    "    \n",
    "    return Rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6849224ae25d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlrp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xs' is not defined"
     ]
    }
   ],
   "source": [
    "lrp(model, xs[0], ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.argmax(np.concatenate([labels_predict]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.zeros_like(classes)\n",
    "i = 0\n",
    "while i < len(classes):\n",
    "    if i < labels_predict.shape[0]:\n",
    "        x, y = valid_generator.next()\n",
    "    else:\n",
    "        x, y = train_generator.next()\n",
    "    y_true[i:i+y.shape[0]] = np.argmax(y, axis=1)\n",
    "    i += y.shape[0]\n",
    "con_mat = tf.math.confusion_matrix(labels=y_true, predictions=classes).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15306f784310>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.argmax(labels_predict, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.matshow(con_mat, cmap='Reds')\n",
    "for (i, j), z in np.ndenumerate(con_mat):\n",
    "    ax.text(j, i, '{:d}'.format(z), ha='center', va='center', color='k', fontsize=16)\n",
    "\n",
    "ax.set_xticks([0, 1, 2])\n",
    "ax.set_yticks([0, 1, 2])\n",
    "ax.set_xticklabels(['Clear', 'Cloudy', 'Rain'])\n",
    "ax.set_yticklabels(['Clear', 'Cloudy', 'Rain'])\n",
    "ax.set_xlabel('Hand label')\n",
    "ax.set_ylabel('Predicted label')\n",
    "fig.savefig('confusion_matrix_1layer_resnet_augmented.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/lambda_stor/data/rjackson/lidar_pngs/5min/training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/lambda_stor/data/rjackson/lidar_pngs/5min/training\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m valid_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/lambda_stor/data/rjackson/lidar_pngs/5min/validation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                                                     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m                                                     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m128\u001b[39m), shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/keras/preprocessing/image.py:976\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    899\u001b[0m                         directory,\n\u001b[1;32m    900\u001b[0m                         target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m                         subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    912\u001b[0m                         interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    913\u001b[0m   \u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m          and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 976\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m      \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m      \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/keras/preprocessing/image.py:394\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    392\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[1;32m    393\u001b[0m   kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDirectoryIterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_data_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pydda_env/lib/python3.9/site-packages/keras_preprocessing/image/directory_iterator.py:115\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    114\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    117\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/lambda_stor/data/rjackson/lidar_pngs/5min/training'"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/training',\n",
    "                                                    class_mode='input', target_size=(1024, 128), shuffle=True,\n",
    "                                                    batch_size=16)\n",
    "valid_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/validation',\n",
    "                                                    class_mode='input', \n",
    "                                                    target_size=(1024, 128), shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net_encoder():\n",
    "    ref_inp = Input(shape=(1024, 128, 3), name='snr')\n",
    "      \n",
    "    x = Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(ref_inp)\n",
    "    l1 = Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_normal',  padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l1)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    l2 = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal',  padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l2)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(16, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    l3 = Conv2D(16, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l3)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(8, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    l4 = Conv2D(8, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l4)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(4, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    l5 = Conv2D(4, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l5)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(2, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    l6 = Conv2D(2, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l6)\n",
    "    encode = MaxPooling2D((2,2), name='encoding')(x)\n",
    "    \n",
    "    x = Conv2DTranspose(2, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(encode)\n",
    "    x = Conv2DTranspose(2, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2DTranspose(4, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = Conv2DTranspose(4, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2DTranspose(8, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = Conv2DTranspose(8, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2DTranspose(16, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = Conv2DTranspose(16, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    ref_out = Conv2DTranspose(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    ref_out = Conv2DTranspose(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(ref_out)\n",
    "    ref_out = BatchNormalization()(ref_out)\n",
    "    ref_out = UpSampling2D((2,2))(ref_out)\n",
    "    ref_out = Conv2DTranspose(64, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(ref_out)\n",
    "    ref_out = Conv2DTranspose(64, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(ref_out)\n",
    "    ref_out = BatchNormalization()(ref_out)\n",
    "    ref_out = UpSampling2D((2,2))(ref_out)\n",
    "    ref_out = Conv2DTranspose(3, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(ref_out)\n",
    "    return Model(ref_inp, ref_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = conv_net_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "snr (InputLayer)             [(None, 1024, 128, 3)]    0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 1024, 128, 64)     1792      \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 1024, 128, 64)     36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 1024, 128, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 512, 64, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 512, 64, 32)       18464     \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 512, 64, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 512, 64, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 256, 32, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 256, 32, 16)       4624      \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 256, 32, 16)       2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 256, 32, 16)       64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 128, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 128, 16, 8)        1160      \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 128, 16, 8)        584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 128, 16, 8)        32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 64, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 64, 8, 4)          292       \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 64, 8, 4)          148       \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 64, 8, 4)          16        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 32, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 32, 4, 2)          74        \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 32, 4, 2)          38        \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 32, 4, 2)          8         \n",
      "_________________________________________________________________\n",
      "encoding (MaxPooling2D)      (None, 16, 2, 2)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_48 (Conv2DT (None, 16, 2, 2)          38        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_49 (Conv2DT (None, 16, 2, 2)          38        \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 16, 2, 2)          8         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling (None, 32, 4, 2)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_50 (Conv2DT (None, 32, 4, 4)          76        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_51 (Conv2DT (None, 32, 4, 4)          148       \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 32, 4, 4)          16        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling (None, 64, 8, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_52 (Conv2DT (None, 64, 8, 8)          296       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_53 (Conv2DT (None, 64, 8, 8)          584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 64, 8, 8)          32        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling (None, 128, 16, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_54 (Conv2DT (None, 128, 16, 16)       1168      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_55 (Conv2DT (None, 128, 16, 16)       2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 128, 16, 16)       64        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_25 (UpSampling (None, 256, 32, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_56 (Conv2DT (None, 256, 32, 32)       4640      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_57 (Conv2DT (None, 256, 32, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 256, 32, 32)       128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_26 (UpSampling (None, 512, 64, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_58 (Conv2DT (None, 512, 64, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_59 (Conv2DT (None, 512, 64, 64)       36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 512, 64, 64)       256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_27 (UpSampling (None, 1024, 128, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_60 (Conv2DT (None, 1024, 128, 3)      1731      \n",
      "=================================================================\n",
      "Total params: 152,391\n",
      "Trainable params: 151,887\n",
      "Non-trainable params: 504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "696/696 [==============================] - 127s 180ms/step - loss: 0.3905 - val_loss: 0.0148\n",
      "\n",
      "Epoch 00001: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-001.hdf5\n",
      "Epoch 2/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00002: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-002.hdf5\n",
      "Epoch 3/150\n",
      "696/696 [==============================] - 124s 179ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "\n",
      "Epoch 00003: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-003.hdf5\n",
      "Epoch 4/150\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 0.0068 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00004: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-004.hdf5\n",
      "Epoch 5/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00005: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-005.hdf5\n",
      "Epoch 6/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00006: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-006.hdf5\n",
      "Epoch 7/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "\n",
      "Epoch 00007: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-007.hdf5\n",
      "Epoch 8/150\n",
      "696/696 [==============================] - 127s 183ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "\n",
      "Epoch 00008: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-008.hdf5\n",
      "Epoch 9/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0011 - val_loss: 8.8905e-04\n",
      "\n",
      "Epoch 00009: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-009.hdf5\n",
      "Epoch 10/150\n",
      "696/696 [==============================] - 128s 183ms/step - loss: 0.0015 - val_loss: 8.8172e-04\n",
      "\n",
      "Epoch 00010: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-010.hdf5\n",
      "Epoch 11/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0014 - val_loss: 6.3344e-04\n",
      "\n",
      "Epoch 00011: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-011.hdf5\n",
      "Epoch 12/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "\n",
      "Epoch 00012: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-012.hdf5\n",
      "Epoch 13/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0016 - val_loss: 8.7753e-04\n",
      "\n",
      "Epoch 00013: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-013.hdf5\n",
      "Epoch 14/150\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 0.0010 - val_loss: 7.7545e-04\n",
      "\n",
      "Epoch 00014: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-014.hdf5\n",
      "Epoch 15/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 9.5329e-04 - val_loss: 8.7721e-04\n",
      "\n",
      "Epoch 00015: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-015.hdf5\n",
      "Epoch 16/150\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 0.0011 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00016: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-016.hdf5\n",
      "Epoch 17/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "\n",
      "Epoch 00017: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-017.hdf5\n",
      "Epoch 18/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0010 - val_loss: 9.5924e-04\n",
      "\n",
      "Epoch 00018: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-018.hdf5\n",
      "Epoch 19/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0017 - val_loss: 8.2644e-04\n",
      "\n",
      "Epoch 00019: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-019.hdf5\n",
      "Epoch 20/150\n",
      "696/696 [==============================] - 126s 180ms/step - loss: 8.0142e-04 - val_loss: 7.8019e-04\n",
      "\n",
      "Epoch 00020: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-020.hdf5\n",
      "Epoch 21/150\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 7.4043e-04 - val_loss: 7.7402e-04\n",
      "\n",
      "Epoch 00021: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-021.hdf5\n",
      "Epoch 22/150\n",
      "696/696 [==============================] - 124s 179ms/step - loss: 7.4143e-04 - val_loss: 7.4148e-04\n",
      "\n",
      "Epoch 00022: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-022.hdf5\n",
      "Epoch 23/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 6.9828e-04 - val_loss: 6.7765e-04\n",
      "\n",
      "Epoch 00023: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-023.hdf5\n",
      "Epoch 24/150\n",
      "696/696 [==============================] - 123s 176ms/step - loss: 6.5932e-04 - val_loss: 6.5417e-04\n",
      "\n",
      "Epoch 00024: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-024.hdf5\n",
      "Epoch 25/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 7.1212e-04 - val_loss: 6.5385e-04\n",
      "\n",
      "Epoch 00025: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-025.hdf5\n",
      "Epoch 26/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00026: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-026.hdf5\n",
      "Epoch 27/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 7.0270e-04 - val_loss: 5.8310e-04\n",
      "\n",
      "Epoch 00027: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-027.hdf5\n",
      "Epoch 28/150\n",
      "696/696 [==============================] - 123s 177ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00028: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-028.hdf5\n",
      "Epoch 29/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00029: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-029.hdf5\n",
      "Epoch 30/150\n",
      "696/696 [==============================] - 123s 177ms/step - loss: 9.0525e-04 - val_loss: 7.4587e-04\n",
      "\n",
      "Epoch 00030: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-030.hdf5\n",
      "Epoch 31/150\n",
      "696/696 [==============================] - 124s 177ms/step - loss: 8.5614e-04 - val_loss: 6.6528e-04\n",
      "\n",
      "Epoch 00031: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-031.hdf5\n",
      "Epoch 32/150\n",
      "696/696 [==============================] - 123s 177ms/step - loss: 7.5662e-04 - val_loss: 6.4786e-04\n",
      "\n",
      "Epoch 00032: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-032.hdf5\n",
      "Epoch 33/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 6.8877e-04 - val_loss: 6.3346e-04\n",
      "\n",
      "Epoch 00033: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-033.hdf5\n",
      "Epoch 34/150\n",
      "696/696 [==============================] - 124s 179ms/step - loss: 6.5213e-04 - val_loss: 5.9801e-04\n",
      "\n",
      "Epoch 00034: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-034.hdf5\n",
      "Epoch 35/150\n",
      "696/696 [==============================] - 124s 179ms/step - loss: 6.1240e-04 - val_loss: 5.4017e-04\n",
      "\n",
      "Epoch 00035: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-035.hdf5\n",
      "Epoch 36/150\n",
      "696/696 [==============================] - 126s 180ms/step - loss: 0.0098 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00036: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-036.hdf5\n",
      "Epoch 37/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00037: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-037.hdf5\n",
      "Epoch 38/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 0.0011 - val_loss: 9.4122e-04\n",
      "\n",
      "Epoch 00038: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-038.hdf5\n",
      "Epoch 39/150\n",
      "696/696 [==============================] - 123s 177ms/step - loss: 8.3711e-04 - val_loss: 7.4356e-04\n",
      "\n",
      "Epoch 00039: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-039.hdf5\n",
      "Epoch 40/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 7.5907e-04 - val_loss: 6.3069e-04\n",
      "\n",
      "Epoch 00040: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-040.hdf5\n",
      "Epoch 41/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0014 - val_loss: 8.9630e-04\n",
      "\n",
      "Epoch 00041: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-041.hdf5\n",
      "Epoch 42/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0028 - val_loss: 9.3771e-04\n",
      "\n",
      "Epoch 00042: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-042.hdf5\n",
      "Epoch 43/150\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 0.0014 - val_loss: 8.7103e-04\n",
      "\n",
      "Epoch 00043: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-043.hdf5\n",
      "Epoch 44/150\n",
      "696/696 [==============================] - 127s 183ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "\n",
      "Epoch 00044: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-044.hdf5\n",
      "Epoch 45/150\n",
      "696/696 [==============================] - 169s 243ms/step - loss: 0.0012 - val_loss: 8.7371e-04\n",
      "\n",
      "Epoch 00045: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-045.hdf5\n",
      "Epoch 46/150\n",
      "696/696 [==============================] - 171s 245ms/step - loss: 0.0012 - val_loss: 9.1495e-04\n",
      "\n",
      "Epoch 00046: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-046.hdf5\n",
      "Epoch 47/150\n",
      "696/696 [==============================] - 166s 239ms/step - loss: 8.7242e-04 - val_loss: 7.9038e-04\n",
      "\n",
      "Epoch 00047: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-047.hdf5\n",
      "Epoch 48/150\n",
      "696/696 [==============================] - 151s 216ms/step - loss: 7.5800e-04 - val_loss: 7.3487e-04\n",
      "\n",
      "Epoch 00048: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-048.hdf5\n",
      "Epoch 49/150\n",
      "696/696 [==============================] - 151s 217ms/step - loss: 6.9002e-04 - val_loss: 6.2775e-04\n",
      "\n",
      "Epoch 00049: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-049.hdf5\n",
      "Epoch 50/150\n",
      "696/696 [==============================] - 163s 234ms/step - loss: 6.2795e-04 - val_loss: 5.9497e-04\n",
      "\n",
      "Epoch 00050: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-050.hdf5\n",
      "Epoch 51/150\n",
      "696/696 [==============================] - 175s 252ms/step - loss: 5.8960e-04 - val_loss: 7.6070e-04\n",
      "\n",
      "Epoch 00051: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-051.hdf5\n",
      "Epoch 52/150\n",
      "696/696 [==============================] - 170s 244ms/step - loss: 6.1853e-04 - val_loss: 5.3217e-04\n",
      "\n",
      "Epoch 00052: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-052.hdf5\n",
      "Epoch 53/150\n",
      "696/696 [==============================] - 165s 237ms/step - loss: 5.4616e-04 - val_loss: 0.0032\n",
      "\n",
      "Epoch 00053: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-053.hdf5\n",
      "Epoch 54/150\n",
      "696/696 [==============================] - 198s 284ms/step - loss: 5.3067e-04 - val_loss: 8.5383e-04\n",
      "\n",
      "Epoch 00054: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-054.hdf5\n",
      "Epoch 55/150\n",
      "696/696 [==============================] - 193s 276ms/step - loss: 5.0544e-04 - val_loss: 5.1993e-04\n",
      "\n",
      "Epoch 00055: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-055.hdf5\n",
      "Epoch 56/150\n",
      "696/696 [==============================] - 200s 287ms/step - loss: 6.0645e-04 - val_loss: 9.1033e-04\n",
      "\n",
      "Epoch 00056: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-056.hdf5\n",
      "Epoch 57/150\n",
      "696/696 [==============================] - 196s 282ms/step - loss: 7.4951e-04 - val_loss: 6.4972e-04\n",
      "\n",
      "Epoch 00057: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-057.hdf5\n",
      "Epoch 58/150\n",
      "696/696 [==============================] - 212s 305ms/step - loss: 6.3638e-04 - val_loss: 8.0937e-04\n",
      "\n",
      "Epoch 00058: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-058.hdf5\n",
      "Epoch 59/150\n",
      "696/696 [==============================] - 199s 285ms/step - loss: 8.4710e-04 - val_loss: 7.2502e-04\n",
      "\n",
      "Epoch 00059: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-059.hdf5\n",
      "Epoch 60/150\n",
      "696/696 [==============================] - 212s 304ms/step - loss: 7.6069e-04 - val_loss: 7.8583e-04\n",
      "\n",
      "Epoch 00060: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-060.hdf5\n",
      "Epoch 61/150\n",
      "696/696 [==============================] - 202s 289ms/step - loss: 8.5975e-04 - val_loss: 9.7566e-04\n",
      "\n",
      "Epoch 00061: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-061.hdf5\n",
      "Epoch 62/150\n",
      "696/696 [==============================] - 190s 273ms/step - loss: 0.0013 - val_loss: 7.9373e-04\n",
      "\n",
      "Epoch 00062: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-062.hdf5\n",
      "Epoch 63/150\n",
      "236/696 [=========>....................] - ETA: 1:38 - loss: 0.0013"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e6f1964aa9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/homes/rjackson/arming_the_edge/models/encoder-%dframes-{epoch:03d}.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                verbose=1)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "               filepath=('/homes/rjackson/arming_the_edge/models/encoder-%dframes-{epoch:03d}.hdf5'),\n",
    "               verbose=1)\n",
    "autoencoder.fit(train_generator, validation_data=valid_generator, epochs=150, callbacks=[checkpointer], initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: /homes/rjackson/arming_the_edge/models/encoder-%dframes-055.hdf5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2b0d9230b1fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/homes/rjackson/arming_the_edge/models/encoder-%dframes-055.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   raise IOError(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 116\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /homes/rjackson/arming_the_edge/models/encoder-%dframes-055.hdf5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "encoder = load_model('/homes/rjackson/arming_the_edge/models/encoder-%dframes-055.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:5'):\n",
    "    pics = autoencoder.predict(train_generator.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(autoencoder.input, autoencoder.get_layer('encoding').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:6'):\n",
    "    encodings = encoder.predict(train_generator)\n",
    "    encodings_validation = encoder.predict(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = np.reshape(encodings, (encodings.shape[0], encodings.shape[1]*encodings.shape[2]*encodings.shape[3]))\n",
    "encodings_validation = np.reshape(encodings_validation, \n",
    "                                  (encodings_validation.shape[0],\n",
    "                                   encodings_validation.shape[1]*encodings_validation.shape[2]*encodings_validation.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_validation = np.reshape(encodings_validation, \n",
    "                                  (encodings_validation.shape[0],\n",
    "                                   encodings_validation.shape[1]*encodings_validation.shape[2]*encodings_validation.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_valid = np.squeeze(np.argwhere(np.isfinite(np.sum(encodings, axis=1))))\n",
    "encodings = encodings[encodings_valid, :]\n",
    "encodings_valid = np.squeeze(np.argwhere(np.isfinite(np.sum(encodings_validation, axis=1))))\n",
    "encodings_validation = encodings_validation[encodings_valid, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11132, 64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.zeros((encodings.shape[0], 3))\n",
    "valid_labels = np.zeros((encodings_validation.shape[0], 3))\n",
    "\n",
    "for i in range(0, encodings.shape[0], 16):\n",
    "    x, y = train_generator.next()\n",
    "    num_y = y.shape[0]\n",
    "    train_labels[i:i+num_y, :] = y[:num_y, :]\n",
    "    \n",
    "for i in range(0, encodings_validation.shape[0], 16):\n",
    "    x, y = valid_generator.next()\n",
    "    num_y = y.shape[0]\n",
    "    valid_labels[i:i+num_y, :] = y[:num_y, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_encodings():\n",
    "    ref_inp = Input(shape=(64,), name='snr')\n",
    "    x = ref_inp\n",
    "    for i in range(10):\n",
    "        x = Dense(2048, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "    out = Dense(3, activation='softmax')(x)\n",
    "    return Model(ref_inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "snr (InputLayer)             [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 2048)              133120    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 3)                 6147      \n",
      "=================================================================\n",
      "Total params: 37,906,435\n",
      "Trainable params: 37,906,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_classifier = nn_encodings()\n",
    "nn_classifier.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "nn_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "348/348 [==============================] - 3s 6ms/step - loss: 0.8497 - accuracy: 0.6895 - val_loss: 0.7815 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00001: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-001.hdf5\n",
      "Epoch 2/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7863 - accuracy: 0.6997 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00002: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-002.hdf5\n",
      "Epoch 3/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7711 - accuracy: 0.7078 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00003: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-003.hdf5\n",
      "Epoch 4/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7740 - accuracy: 0.6999 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00004: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-004.hdf5\n",
      "Epoch 5/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7842 - accuracy: 0.6948 - val_loss: 0.7917 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00005: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-005.hdf5\n",
      "Epoch 6/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7677 - accuracy: 0.7079 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00006: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-006.hdf5\n",
      "Epoch 7/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7697 - accuracy: 0.7066 - val_loss: 0.7802 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00007: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-007.hdf5\n",
      "Epoch 8/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7729 - accuracy: 0.7038 - val_loss: 0.7807 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00008: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-008.hdf5\n",
      "Epoch 9/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7600 - accuracy: 0.7091 - val_loss: 0.7827 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00009: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-009.hdf5\n",
      "Epoch 10/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7805 - accuracy: 0.7015 - val_loss: 0.7850 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00010: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-010.hdf5\n",
      "Epoch 11/150\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 0.7725 - accuracy: 0.7039 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00011: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-011.hdf5\n",
      "Epoch 12/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7595 - accuracy: 0.7094 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00012: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-012.hdf5\n",
      "Epoch 13/150\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 0.7745 - accuracy: 0.7008 - val_loss: 0.7829 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00013: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-013.hdf5\n",
      "Epoch 14/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7567 - accuracy: 0.7118 - val_loss: 0.7815 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00014: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-014.hdf5\n",
      "Epoch 15/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7774 - accuracy: 0.6979 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00015: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-015.hdf5\n",
      "Epoch 16/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7688 - accuracy: 0.7029 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00016: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-016.hdf5\n",
      "Epoch 17/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7738 - accuracy: 0.6994 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00017: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-017.hdf5\n",
      "Epoch 18/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7749 - accuracy: 0.6993 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00018: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-018.hdf5\n",
      "Epoch 19/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7624 - accuracy: 0.7098 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00019: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-019.hdf5\n",
      "Epoch 20/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7703 - accuracy: 0.7034 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00020: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-020.hdf5\n",
      "Epoch 21/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7701 - accuracy: 0.7023 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00021: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-021.hdf5\n",
      "Epoch 22/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7801 - accuracy: 0.6997 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00022: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-022.hdf5\n",
      "Epoch 23/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7745 - accuracy: 0.7005 - val_loss: 0.7804 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00023: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-023.hdf5\n",
      "Epoch 24/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7773 - accuracy: 0.6973 - val_loss: 0.7805 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00024: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-024.hdf5\n",
      "Epoch 25/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7746 - accuracy: 0.7031 - val_loss: 0.7830 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00025: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-025.hdf5\n",
      "Epoch 26/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7690 - accuracy: 0.7073 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00026: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-026.hdf5\n",
      "Epoch 27/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7649 - accuracy: 0.7075 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00027: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-027.hdf5\n",
      "Epoch 28/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7658 - accuracy: 0.7057 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00028: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-028.hdf5\n",
      "Epoch 29/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7789 - accuracy: 0.6999 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00029: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-029.hdf5\n",
      "Epoch 30/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7836 - accuracy: 0.6967 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00030: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-030.hdf5\n",
      "Epoch 31/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7635 - accuracy: 0.7066 - val_loss: 0.7802 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00031: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-031.hdf5\n",
      "Epoch 32/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7707 - accuracy: 0.7016 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00032: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-032.hdf5\n",
      "Epoch 33/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7686 - accuracy: 0.7040 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00033: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-033.hdf5\n",
      "Epoch 34/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7678 - accuracy: 0.7049 - val_loss: 0.7805 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00034: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-034.hdf5\n",
      "Epoch 35/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7763 - accuracy: 0.7030 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00035: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-035.hdf5\n",
      "Epoch 36/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7678 - accuracy: 0.7024 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00036: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-036.hdf5\n",
      "Epoch 37/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7650 - accuracy: 0.7048 - val_loss: 0.7818 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00037: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-037.hdf5\n",
      "Epoch 38/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7602 - accuracy: 0.7092 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00038: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-038.hdf5\n",
      "Epoch 39/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7620 - accuracy: 0.7093 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00039: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-039.hdf5\n",
      "Epoch 40/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7894 - accuracy: 0.6931 - val_loss: 0.7801 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00040: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-040.hdf5\n",
      "Epoch 41/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7687 - accuracy: 0.7052 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00041: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-041.hdf5\n",
      "Epoch 42/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7694 - accuracy: 0.7043 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00042: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-042.hdf5\n",
      "Epoch 43/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7828 - accuracy: 0.6954 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00043: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-043.hdf5\n",
      "Epoch 44/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7632 - accuracy: 0.7101 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00044: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-044.hdf5\n",
      "Epoch 45/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7599 - accuracy: 0.7067 - val_loss: 0.7805 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00045: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-045.hdf5\n",
      "Epoch 46/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7627 - accuracy: 0.7060 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00046: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-046.hdf5\n",
      "Epoch 47/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7742 - accuracy: 0.7018 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00047: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-047.hdf5\n",
      "Epoch 48/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7623 - accuracy: 0.7066 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00048: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-048.hdf5\n",
      "Epoch 49/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7611 - accuracy: 0.7083 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00049: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-049.hdf5\n",
      "Epoch 50/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7856 - accuracy: 0.6940 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00050: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-050.hdf5\n",
      "Epoch 51/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7760 - accuracy: 0.6992 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00051: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-051.hdf5\n",
      "Epoch 52/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7714 - accuracy: 0.7011 - val_loss: 0.7815 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00052: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-052.hdf5\n",
      "Epoch 53/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7603 - accuracy: 0.7107 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00053: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-053.hdf5\n",
      "Epoch 54/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7618 - accuracy: 0.7104 - val_loss: 0.7801 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00054: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-054.hdf5\n",
      "Epoch 55/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7789 - accuracy: 0.6980 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00055: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-055.hdf5\n",
      "Epoch 56/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7535 - accuracy: 0.7152 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00056: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-056.hdf5\n",
      "Epoch 57/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7620 - accuracy: 0.7063 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00057: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-057.hdf5\n",
      "Epoch 58/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7617 - accuracy: 0.7063 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00058: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-058.hdf5\n",
      "Epoch 59/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7689 - accuracy: 0.7040 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00059: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-059.hdf5\n",
      "Epoch 60/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7709 - accuracy: 0.7054 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00060: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-060.hdf5\n",
      "Epoch 61/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7754 - accuracy: 0.6975 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00061: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-061.hdf5\n",
      "Epoch 62/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7680 - accuracy: 0.7053 - val_loss: 0.7801 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00062: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-062.hdf5\n",
      "Epoch 63/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7768 - accuracy: 0.6974 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00063: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-063.hdf5\n",
      "Epoch 64/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7765 - accuracy: 0.6987 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00064: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-064.hdf5\n",
      "Epoch 65/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7733 - accuracy: 0.7016 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00065: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-065.hdf5\n",
      "Epoch 66/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7723 - accuracy: 0.7041 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00066: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-066.hdf5\n",
      "Epoch 67/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7667 - accuracy: 0.7044 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00067: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-067.hdf5\n",
      "Epoch 68/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7643 - accuracy: 0.7065 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00068: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-068.hdf5\n",
      "Epoch 69/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7630 - accuracy: 0.7115 - val_loss: 0.7812 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00069: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-069.hdf5\n",
      "Epoch 70/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7709 - accuracy: 0.7034 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00070: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-070.hdf5\n",
      "Epoch 71/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7661 - accuracy: 0.7057 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00071: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-071.hdf5\n",
      "Epoch 72/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7678 - accuracy: 0.7047 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00072: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-072.hdf5\n",
      "Epoch 73/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7674 - accuracy: 0.7053 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00073: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-073.hdf5\n",
      "Epoch 74/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7756 - accuracy: 0.7009 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00074: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-074.hdf5\n",
      "Epoch 75/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7761 - accuracy: 0.6990 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00075: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-075.hdf5\n",
      "Epoch 76/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7727 - accuracy: 0.7021 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00076: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-076.hdf5\n",
      "Epoch 77/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7705 - accuracy: 0.7008 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00077: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-077.hdf5\n",
      "Epoch 78/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7653 - accuracy: 0.7034 - val_loss: 0.7801 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00078: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-078.hdf5\n",
      "Epoch 79/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7733 - accuracy: 0.6987 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00079: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-079.hdf5\n",
      "Epoch 80/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7526 - accuracy: 0.7165 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00080: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-080.hdf5\n",
      "Epoch 81/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7754 - accuracy: 0.6968 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00081: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-081.hdf5\n",
      "Epoch 82/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7741 - accuracy: 0.6976 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00082: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-082.hdf5\n",
      "Epoch 83/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7632 - accuracy: 0.7066 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00083: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-083.hdf5\n",
      "Epoch 84/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7729 - accuracy: 0.7001 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00084: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-084.hdf5\n",
      "Epoch 85/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7626 - accuracy: 0.7070 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00085: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-085.hdf5\n",
      "Epoch 86/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7729 - accuracy: 0.7000 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00086: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-086.hdf5\n",
      "Epoch 87/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7819 - accuracy: 0.6953 - val_loss: 0.7803 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00087: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-087.hdf5\n",
      "Epoch 88/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7611 - accuracy: 0.7082 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00088: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-088.hdf5\n",
      "Epoch 89/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7733 - accuracy: 0.6985 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00089: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-089.hdf5\n",
      "Epoch 90/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7699 - accuracy: 0.7054 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00090: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-090.hdf5\n",
      "Epoch 91/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7703 - accuracy: 0.7058 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00091: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-091.hdf5\n",
      "Epoch 92/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7678 - accuracy: 0.7008 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00092: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-092.hdf5\n",
      "Epoch 93/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7637 - accuracy: 0.7028 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00093: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-093.hdf5\n",
      "Epoch 94/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7697 - accuracy: 0.7018 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00094: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-094.hdf5\n",
      "Epoch 95/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7659 - accuracy: 0.7047 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00095: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-095.hdf5\n",
      "Epoch 96/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7588 - accuracy: 0.7094 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00096: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-096.hdf5\n",
      "Epoch 97/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7619 - accuracy: 0.7064 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00097: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-097.hdf5\n",
      "Epoch 98/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7593 - accuracy: 0.7087 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00098: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-098.hdf5\n",
      "Epoch 99/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7630 - accuracy: 0.7048 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00099: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-099.hdf5\n",
      "Epoch 100/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7711 - accuracy: 0.7046 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00100: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-100.hdf5\n",
      "Epoch 101/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7643 - accuracy: 0.7062 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00101: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-101.hdf5\n",
      "Epoch 102/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7591 - accuracy: 0.7080 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00102: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-102.hdf5\n",
      "Epoch 103/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7623 - accuracy: 0.7082 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00103: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-103.hdf5\n",
      "Epoch 104/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7674 - accuracy: 0.7041 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00104: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-104.hdf5\n",
      "Epoch 105/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7723 - accuracy: 0.7022 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00105: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-105.hdf5\n",
      "Epoch 106/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7647 - accuracy: 0.7044 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00106: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-106.hdf5\n",
      "Epoch 107/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7715 - accuracy: 0.7063 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00107: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-107.hdf5\n",
      "Epoch 108/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7751 - accuracy: 0.7039 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00108: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-108.hdf5\n",
      "Epoch 109/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7700 - accuracy: 0.7044 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00109: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-109.hdf5\n",
      "Epoch 110/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7638 - accuracy: 0.7068 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00110: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-110.hdf5\n",
      "Epoch 111/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7695 - accuracy: 0.7037 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00111: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-111.hdf5\n",
      "Epoch 112/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7801 - accuracy: 0.6958 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00112: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-112.hdf5\n",
      "Epoch 113/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7820 - accuracy: 0.6936 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00113: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-113.hdf5\n",
      "Epoch 114/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7739 - accuracy: 0.6967 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00114: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-114.hdf5\n",
      "Epoch 115/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7703 - accuracy: 0.7026 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00115: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-115.hdf5\n",
      "Epoch 116/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7673 - accuracy: 0.7062 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00116: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-116.hdf5\n",
      "Epoch 117/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7667 - accuracy: 0.7031 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00117: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-117.hdf5\n",
      "Epoch 118/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7698 - accuracy: 0.7010 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00118: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-118.hdf5\n",
      "Epoch 119/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7622 - accuracy: 0.7083 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00119: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-119.hdf5\n",
      "Epoch 120/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7644 - accuracy: 0.7048 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00120: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-120.hdf5\n",
      "Epoch 121/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7832 - accuracy: 0.6936 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00121: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-121.hdf5\n",
      "Epoch 122/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7671 - accuracy: 0.7049 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00122: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-122.hdf5\n",
      "Epoch 123/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7785 - accuracy: 0.7019 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00123: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-123.hdf5\n",
      "Epoch 124/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7670 - accuracy: 0.7044 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00124: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-124.hdf5\n",
      "Epoch 125/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7701 - accuracy: 0.7002 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00125: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-125.hdf5\n",
      "Epoch 126/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7631 - accuracy: 0.7066 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00126: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-126.hdf5\n",
      "Epoch 127/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7627 - accuracy: 0.7029 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00127: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-127.hdf5\n",
      "Epoch 128/150\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 0.7689 - accuracy: 0.7027 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00128: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-128.hdf5\n",
      "Epoch 129/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7679 - accuracy: 0.7031 - val_loss: 0.7801 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00129: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-129.hdf5\n",
      "Epoch 130/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7749 - accuracy: 0.6994 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00130: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-130.hdf5\n",
      "Epoch 131/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7719 - accuracy: 0.7033 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00131: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-131.hdf5\n",
      "Epoch 132/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7782 - accuracy: 0.6963 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00132: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-132.hdf5\n",
      "Epoch 133/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7659 - accuracy: 0.7053 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00133: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-133.hdf5\n",
      "Epoch 134/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7727 - accuracy: 0.7011 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00134: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-134.hdf5\n",
      "Epoch 135/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7669 - accuracy: 0.7025 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00135: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-135.hdf5\n",
      "Epoch 136/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7580 - accuracy: 0.7066 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00136: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-136.hdf5\n",
      "Epoch 137/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7690 - accuracy: 0.7042 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00137: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-137.hdf5\n",
      "Epoch 138/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7714 - accuracy: 0.7035 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00138: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-138.hdf5\n",
      "Epoch 139/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7670 - accuracy: 0.7047 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00139: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-139.hdf5\n",
      "Epoch 140/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7606 - accuracy: 0.7118 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00140: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-140.hdf5\n",
      "Epoch 141/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7605 - accuracy: 0.7087 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00141: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-141.hdf5\n",
      "Epoch 142/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7672 - accuracy: 0.7023 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00142: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-142.hdf5\n",
      "Epoch 143/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7625 - accuracy: 0.7085 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00143: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-143.hdf5\n",
      "Epoch 144/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7633 - accuracy: 0.7073 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00144: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-144.hdf5\n",
      "Epoch 145/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7686 - accuracy: 0.7048 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00145: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-145.hdf5\n",
      "Epoch 146/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7697 - accuracy: 0.7011 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00146: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-146.hdf5\n",
      "Epoch 147/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7616 - accuracy: 0.7062 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00147: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-147.hdf5\n",
      "Epoch 148/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7704 - accuracy: 0.7023 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00148: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-148.hdf5\n",
      "Epoch 149/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7619 - accuracy: 0.7059 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00149: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-149.hdf5\n",
      "Epoch 150/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7795 - accuracy: 0.6977 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00150: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-150.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b34f42cd0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "               filepath=('/homes/rjackson/arming_the_edge/models/classifier-encodings-{epoch:03d}.hdf5'),\n",
    "               verbose=1)\n",
    "nn_classifier.fit(encodings, train_labels, validation_data=(encodings_validation, valid_labels), epochs=150,\n",
    "                 callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "SSE = np.zeros(20)\n",
    "\n",
    "for i in range(1, 21):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(encodings)\n",
    "    SSE[i-1] = kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total squared error')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 21), SSE)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Total squared error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "kmeans = KMeans(n_clusters=num_classes)\n",
    "kmeans.fit(encodings)\n",
    "classes = kmeans.predict(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9843138 , 0.9843138 , 0.9843138 ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9843138 , 0.9843138 , 0.9843138 ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9450981 , 0.9450981 , 0.9450981 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9058824 , 0.9058824 , 0.9058824 ],\n",
       "          ...,\n",
       "          [0.9568628 , 0.9568628 , 0.9568628 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.90196085, 0.90196085, 0.90196085]],\n",
       " \n",
       "         [[0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.909804  , 0.909804  , 0.909804  ],\n",
       "          ...,\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.91372555, 0.91372555, 0.91372555]],\n",
       " \n",
       "         [[0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.909804  , 0.909804  , 0.909804  ],\n",
       "          ...,\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.91372555, 0.91372555, 0.91372555]]]], dtype=float32),\n",
       " array([[[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9843138 , 0.9843138 , 0.9843138 ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9843138 , 0.9843138 , 0.9843138 ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9450981 , 0.9450981 , 0.9450981 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9058824 , 0.9058824 , 0.9058824 ],\n",
       "          ...,\n",
       "          [0.9568628 , 0.9568628 , 0.9568628 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.90196085, 0.90196085, 0.90196085]],\n",
       " \n",
       "         [[0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.909804  , 0.909804  , 0.909804  ],\n",
       "          ...,\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.91372555, 0.91372555, 0.91372555]],\n",
       " \n",
       "         [[0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.909804  , 0.909804  , 0.909804  ],\n",
       "          ...,\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.91372555, 0.91372555, 0.91372555]]]], dtype=float32))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x2160 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_class = 2\n",
    "where_class = np.argwhere(classes == my_class)\n",
    "fig, ax = plt.subplots(4, 4, figsize=(12,30))\n",
    "for i in range(16):\n",
    "    ax[int(i / 4), i % 4].imshow(np.squeeze(train_generator[int(where_class[i] / 16)][0][where_class[i] % 16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
