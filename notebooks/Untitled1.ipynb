{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN classifier for arming the edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/rjackson/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from keras_unet.models import custom_unet\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Add, Activation, Concatenate, Flatten\n",
    "from tensorflow.keras.layers import Cropping2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Reshape\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"  \n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop white space out of all images if not already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22605\n"
     ]
    }
   ],
   "source": [
    "raw_images = '/lambda_stor/data/rjackson/lidar_pngs/5min/**/*.png'\n",
    "raw_img_list = glob(raw_images, recursive=True)\n",
    "print(len(raw_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in raw_img_list:\n",
    "    yourImage = Image.open(image_file)\n",
    "    yourImage.crop((130, 40, 1320, 410)).save(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment training images for cloudy by doing a left-right flip, same for rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7854\n"
     ]
    }
   ],
   "source": [
    "cloudy_data_path = '/lambda_stor/data/rjackson/lidar_pngs/5min_snr/training/clear/*.png'\n",
    "cloud_images = glob(cloudy_data_path)\n",
    "print(len(cloud_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/7854\n",
      "200/7854\n",
      "300/7854\n",
      "400/7854\n",
      "500/7854\n",
      "600/7854\n",
      "700/7854\n",
      "800/7854\n",
      "900/7854\n",
      "1000/7854\n",
      "1100/7854\n",
      "1200/7854\n",
      "1300/7854\n",
      "1400/7854\n",
      "1500/7854\n",
      "1600/7854\n",
      "1700/7854\n",
      "1800/7854\n",
      "1900/7854\n",
      "2000/7854\n",
      "2100/7854\n",
      "2200/7854\n",
      "2300/7854\n",
      "2400/7854\n",
      "2500/7854\n",
      "2600/7854\n",
      "2700/7854\n",
      "2800/7854\n",
      "2900/7854\n",
      "3000/7854\n",
      "3100/7854\n",
      "3200/7854\n",
      "3300/7854\n",
      "3400/7854\n",
      "3500/7854\n",
      "3600/7854\n",
      "3700/7854\n",
      "3800/7854\n",
      "3900/7854\n",
      "4000/7854\n",
      "4100/7854\n",
      "4200/7854\n",
      "4300/7854\n",
      "4400/7854\n",
      "4500/7854\n",
      "4600/7854\n",
      "4700/7854\n",
      "4800/7854\n",
      "4900/7854\n",
      "5000/7854\n",
      "5100/7854\n",
      "5200/7854\n",
      "5300/7854\n",
      "5400/7854\n",
      "5500/7854\n",
      "5600/7854\n",
      "5700/7854\n",
      "5800/7854\n",
      "5900/7854\n",
      "6000/7854\n",
      "6100/7854\n",
      "6200/7854\n",
      "6300/7854\n",
      "6400/7854\n",
      "6500/7854\n",
      "6600/7854\n",
      "6700/7854\n",
      "6800/7854\n",
      "6900/7854\n",
      "7000/7854\n",
      "7100/7854\n",
      "7200/7854\n",
      "7300/7854\n",
      "7400/7854\n",
      "7500/7854\n",
      "7600/7854\n",
      "7700/7854\n",
      "7800/7854\n"
     ]
    }
   ],
   "source": [
    "train_datagen_flip = ImageDataGenerator(rescale=1/255., \n",
    "                                        horizontal_flip=True, \n",
    "                                        width_shift_range=[-5, 5])\n",
    "j = 0\n",
    "for image in cloud_images:\n",
    "    img = load_img(image)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape) \n",
    "\n",
    "    i = 0\n",
    "    for batch in train_datagen_flip.flow(x, batch_size=1,\n",
    "                                        save_to_dir='/lambda_stor/data/rjackson/lidar_pngs/augmented/clear/',\n",
    "                                        save_prefix=str(j) + str(i), save_format='png'):\n",
    "        i += 1\n",
    "        if i > 5:\n",
    "            break\n",
    "    \n",
    "    j += 1\n",
    "    if j % 100 == 0:\n",
    "        print('%d/%d' % (j, len(cloud_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_flip = ImageDataGenerator(rescale=1/255., \n",
    "                                        horizontal_flip=True, \n",
    "                                        brightness_range=[0.95, 1.05], width_shift_range=[-5, 5])\n",
    "j = 0\n",
    "fig, ax = plt.subplots(6, 6, figsize=(15, 20))\n",
    "image = cloud_images[0]\n",
    "img = load_img(image)\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape) \n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for batch in train_datagen_flip.flow(x, batch_size=1):\n",
    "    ax[i, j].imshow(batch[0])\n",
    "    i = i + 1\n",
    "    if i >= 6:\n",
    "        j = j + 1\n",
    "        i = 0\n",
    "    if j >= 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 566, 4)\n"
     ]
    }
   ],
   "source": [
    "img=mpimg.imread('/lambda_stor/data/rjackson/lidar_pngs/5min/training/cloudy/sgpdlacfC1.a1.20170924.220114.moments11.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "print(img.shape)\n",
    "# (150, 50), (1300, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 3 classes.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "imshow() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9f05ac312e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                     \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cloudy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                     target_size=(256, 128), shuffle=True, batch_size=16)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: imshow() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "train_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/training',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloudy', 'rain'],\n",
    "                                                    target_size=(256, 128), shuffle=True, batch_size=16)\n",
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_datagen_flip = ImageDataGenerator(rescale=1/255., horizontal_flip=True, width_shift_range=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10740 images belonging to 3 classes.\n",
      "Found 2784 images belonging to 3 classes.\n",
      "Found 5938 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min_snr/training',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloudy', 'rain'],\n",
    "                                                    target_size=(256, 128), shuffle=True, batch_size=32)\n",
    "valid_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min_snr/validation',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloudy', 'rain'],\n",
    "                                                    target_size=(256, 128), shuffle=True, batch_size=32)\n",
    "train_generator_flip = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min_undersample/training',\n",
    "                                                    class_mode='categorical', classes=['clear', 'cloudy', 'rain'],\n",
    "                                                    target_size=(256, 128), batch_size=32)\n",
    "#valid_generator_flip = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/augmented/',\n",
    "#                                                    class_mode='categorical', classes=['clear', 'cloudy', 'rain'],\n",
    "#                                                    target_size=(512, 128), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(IMG_HEIGHT=256, IMG_WIDTH=128):\n",
    "    restnet = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3))\n",
    "    restnet.summary()\n",
    "    output = restnet.layers[-1].output\n",
    "    output = Flatten()(output)\n",
    "    restnet = Model(restnet.input,output)\n",
    "    for layer in restnet.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(restnet)\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(3, name='targets',\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal'))\n",
    "    return model\n",
    "\n",
    "def vgg(IMG_HEIGHT=256, IMG_WIDTH=128):\n",
    "    restnet = VGG19(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3))\n",
    "    restnet.summary()\n",
    "    output = restnet.layers[-1].output\n",
    "    output = Flatten()(output)\n",
    "    restnet = Model(restnet.input,output)\n",
    "    for layer in restnet.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(restnet)\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(3, name='targets',\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net_layer(inp, skip=False, num_channels=2, batch_norm=True,\n",
    "                   activate=True, add_layer=None):\n",
    "    x = Conv2D(num_channels, kernel_size=(2, 2), kernel_initializer='he_normal', padding='same',\n",
    "              kernel_regularizer=l2(0.01))(inp)\n",
    "    x = Conv2D(num_channels, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same',\n",
    "              kernel_regularizer=l2(0.01))(x)\n",
    "    if batch_norm:\n",
    "        x = Dropout(0.3)(x)\n",
    "    if activate:\n",
    "        if add_layer is True:\n",
    "            x = Add()([x, inp])\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "    return x\n",
    "\n",
    "def conv_net_layer_up(inp, skip=False, num_channels=2, batch_norm=True,\n",
    "                      activate=True, add_layer=None):\n",
    "    x = Conv2D(1, kernel_size=(3, 3), kernel_initializer='he_normal')(inp)\n",
    "    x = Conv2D(num_channels, kernel_size=(3, 3), kernel_initializer='he_normal')(x)\n",
    "    x = Conv2D(3, kernel_size=(3, 3), kernel_initializer='he_normal')(x)\n",
    "    if batch_norm:\n",
    "        x = Dropout(0.3)(x)\n",
    "    if activate:\n",
    "        if add_layer is not None:\n",
    "            x = Add()([x, inp])\n",
    "        x = Activation('relu')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "    return x\n",
    "\n",
    "def conv_net_classifier(velocity=False):\n",
    "    ref_inp = Input(shape=(256, 128, 3), name='snr')\n",
    "          \n",
    "    layer2 = conv_net_layer(ref_inp, num_channels=16, batch_norm=True,\n",
    "             activate=True, add_layer=False)\n",
    "    layer2 = conv_net_layer(layer2, num_channels=16, batch_norm=True,\n",
    "             activate=True, add_layer=False)\n",
    "    layer2 = conv_net_layer(layer2, num_channels=16, batch_norm=True,\n",
    "             activate=True, add_layer=False)\n",
    "    layer2 = conv_net_layer(layer2, num_channels=16, batch_norm=True,\n",
    "             activate=True, add_layer=False)\n",
    "    layer2 = conv_net_layer(layer2, num_channels=16, batch_norm=True,\n",
    "             activate=True, add_layer=False)\n",
    "    ref_out = conv_net_layer(layer2, num_channels=16, add_layer=False, batch_norm=True, activate=False)\n",
    "    #ref_skip = Activation('relu')(ref_skip)\n",
    "    #ref_out = Add()([ref_out, ref_skip])\n",
    "    #ref_out = Activation('relu')(ref_out)\n",
    "    if velocity:   \n",
    "        x = Concatenate()([ref_out, vel_out])\n",
    "    else:\n",
    "        x = ref_out \n",
    "    \n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = Flatten()(x)\n",
    "    #x = AveragePooling2D()(x)\n",
    "    outputs = Dense(32, activation='relu')(x)\n",
    "    outputs = Dropout(0.3)(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = Dropout(0.3)(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = Dropout(0.3)(outputs)\n",
    "    outputs = Dense(3, name='targets',\n",
    "                    activation='softmax',\n",
    "                    )(outputs)\n",
    "\n",
    "    #x = Dense(2, activation='relu')(x)\n",
    "    #x = Dense(3, activation='softmax', name='label')(x)\n",
    "    if velocity:\n",
    "        return Model(inputs=[ref_in, vel_in], outputs=outputs)\n",
    "    else:\n",
    "        return Model(ref_inp, outputs)\n",
    "\n",
    "def combine_generator(gen1, gen2):\n",
    "    while True:\n",
    "        yield(next(gen1), next(gen2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 64, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 64, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 64, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 8, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Functional)         (None, 16384)             20024384  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "targets (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 28,940,355\n",
      "Trainable params: 13,635,587\n",
      "Non-trainable params: 15,304,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vgg()\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "336/336 [==============================] - 21s 60ms/step - loss: 0.5003 - accuracy: 0.8820 - val_loss: 0.3155 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00001: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-001.hdf5\n",
      "Epoch 2/2000\n",
      "336/336 [==============================] - 20s 59ms/step - loss: 0.3044 - accuracy: 0.9003 - val_loss: 0.2950 - val_accuracy: 0.8991\n",
      "\n",
      "Epoch 00002: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-002.hdf5\n",
      "Epoch 3/2000\n",
      "336/336 [==============================] - 20s 60ms/step - loss: 0.3181 - accuracy: 0.8990 - val_loss: 0.3163 - val_accuracy: 0.8804\n",
      "\n",
      "Epoch 00003: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-003.hdf5\n",
      "Epoch 4/2000\n",
      "336/336 [==============================] - 20s 59ms/step - loss: 0.2964 - accuracy: 0.9036 - val_loss: 0.3106 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00004: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-004.hdf5\n",
      "Epoch 5/2000\n",
      "336/336 [==============================] - 20s 59ms/step - loss: 0.3307 - accuracy: 0.8972 - val_loss: 0.2986 - val_accuracy: 0.8998\n",
      "\n",
      "Epoch 00005: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-005.hdf5\n",
      "Epoch 6/2000\n",
      "336/336 [==============================] - 20s 59ms/step - loss: 0.2829 - accuracy: 0.9090 - val_loss: 0.3208 - val_accuracy: 0.8901\n",
      "\n",
      "Epoch 00006: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-006.hdf5\n",
      "Epoch 7/2000\n",
      "336/336 [==============================] - 20s 58ms/step - loss: 0.4509 - accuracy: 0.8962 - val_loss: 0.3089 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00007: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-007.hdf5\n",
      "Epoch 8/2000\n",
      "336/336 [==============================] - 19s 58ms/step - loss: 0.2832 - accuracy: 0.9092 - val_loss: 0.3197 - val_accuracy: 0.9030\n",
      "\n",
      "Epoch 00008: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-008.hdf5\n",
      "Epoch 9/2000\n",
      "336/336 [==============================] - 20s 60ms/step - loss: 0.2855 - accuracy: 0.9128 - val_loss: 0.2997 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00009: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-009.hdf5\n",
      "Epoch 10/2000\n",
      "336/336 [==============================] - 21s 62ms/step - loss: 0.2743 - accuracy: 0.9167 - val_loss: 0.2804 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00010: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-010.hdf5\n",
      "Epoch 11/2000\n",
      "336/336 [==============================] - 20s 60ms/step - loss: 0.2572 - accuracy: 0.9153 - val_loss: 0.2927 - val_accuracy: 0.9066\n",
      "\n",
      "Epoch 00011: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-011.hdf5\n",
      "Epoch 12/2000\n",
      "336/336 [==============================] - 20s 61ms/step - loss: 0.2802 - accuracy: 0.9123 - val_loss: 0.2826 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00012: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-012.hdf5\n",
      "Epoch 13/2000\n",
      "336/336 [==============================] - 20s 59ms/step - loss: 0.2719 - accuracy: 0.9143 - val_loss: 0.2693 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00013: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-013.hdf5\n",
      "Epoch 14/2000\n",
      "336/336 [==============================] - 20s 61ms/step - loss: 0.2532 - accuracy: 0.9194 - val_loss: 0.2710 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00014: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-014.hdf5\n",
      "Epoch 15/2000\n",
      "336/336 [==============================] - 20s 59ms/step - loss: 0.2460 - accuracy: 0.9193 - val_loss: 0.3028 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00015: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-015.hdf5\n",
      "Epoch 16/2000\n",
      "336/336 [==============================] - 20s 61ms/step - loss: 0.2699 - accuracy: 0.9180 - val_loss: 0.3286 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00016: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-016.hdf5\n",
      "Epoch 17/2000\n",
      "336/336 [==============================] - 20s 59ms/step - loss: 0.2643 - accuracy: 0.9175 - val_loss: 0.2870 - val_accuracy: 0.9027\n",
      "\n",
      "Epoch 00017: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-017.hdf5\n",
      "Epoch 18/2000\n",
      "336/336 [==============================] - 20s 60ms/step - loss: 0.2444 - accuracy: 0.9191 - val_loss: 0.2922 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00018: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-018.hdf5\n",
      "Epoch 19/2000\n",
      "336/336 [==============================] - 20s 59ms/step - loss: 0.2471 - accuracy: 0.9239 - val_loss: 0.3207 - val_accuracy: 0.9102\n",
      "\n",
      "Epoch 00019: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-019.hdf5\n",
      "Epoch 20/2000\n",
      "336/336 [==============================] - 20s 60ms/step - loss: 0.2393 - accuracy: 0.9243 - val_loss: 0.2800 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00020: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-020.hdf5\n",
      "Epoch 21/2000\n",
      "336/336 [==============================] - 20s 59ms/step - loss: 0.2403 - accuracy: 0.9240 - val_loss: 0.2804 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00021: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-021.hdf5\n",
      "Epoch 22/2000\n",
      "336/336 [==============================] - 20s 59ms/step - loss: 0.2589 - accuracy: 0.9192 - val_loss: 0.3119 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00022: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-022.hdf5\n",
      "Epoch 23/2000\n",
      "336/336 [==============================] - 20s 61ms/step - loss: 0.2350 - accuracy: 0.9257 - val_loss: 0.2773 - val_accuracy: 0.9066\n",
      "\n",
      "Epoch 00023: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-023.hdf5\n",
      "Epoch 24/2000\n",
      "336/336 [==============================] - 20s 60ms/step - loss: 0.2346 - accuracy: 0.9226 - val_loss: 0.2706 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00024: saving model to /homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-024.hdf5\n"
     ]
    }
   ],
   "source": [
    "class_weight = {0: 1.,\n",
    "                1: 3.,\n",
    "                2: 5.}\n",
    "checkpointer = ModelCheckpoint(\n",
    "               filepath=('/homes/rjackson/arming_the_edge/models/res-combined-1layer-{epoch:03d}.hdf5'),\n",
    "               verbose=1)\n",
    "early_stopping = EarlyStopping(restore_best_weights=True, patience=100, monitor=\"val_accuracy\", mode=\"max\")\n",
    "history = model.fit(train_generator, validation_data=valid_generator, epochs=2000,\n",
    "          callbacks=[checkpointer, early_stopping], initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = model.predict(valid_generator)\n",
    "labels_train = model.predict(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/homes/rjackson/arming_the_edge/models/vgg19-combined-1layer-070.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='training')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.75, 1])\n",
    "plt.legend()\n",
    "plt.title('Vgg19 3 layers tuned')\n",
    "plt.savefig('Vgg193layers.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layerwise relevance propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fad6000c950>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a61d1d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fafd452b5d0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fad5a583410>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fad5a583550>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fad60faac90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad6118d2d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad60b671d0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fad5a58a950>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fad5a58aa90>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fad5a58abd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a58d190>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a58d8d0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fad5a58dfd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fad5a583f10>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fad5a5ffcd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a588750>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a588dd0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fad5a5934d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fad5a593610>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fad5a593790>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a593d50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a59e450>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fad5a59ebd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fad5a59ed10>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fad5a59ed90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a5a0450>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fad5a5a0ad0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fad60faaa10>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x7fad5a5a54d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fad5a5a5690>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fad5a5a5b10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fad5a5a5d90>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fad5a53e190>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fad5a53e3d0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fad5a53e810>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fad5a53ea50>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for i in range(10):\n",
    "    x, y = valid_generator.next()\n",
    "    xs.append(tf.convert_to_tensor(x))\n",
    "    ys.append(tf.convert_to_tensor(y))\n",
    "#x = np.stack(x)\n",
    "#y = np.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_MODULE_IGNORED_PROPERTIES',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activity_regularizer',\n",
       " '_add_trackable',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_auto_track_sub_layers',\n",
       " '_autocast',\n",
       " '_autographed_call',\n",
       " '_build_input_shape',\n",
       " '_call_accepts_kwargs',\n",
       " '_call_arg_was_passed',\n",
       " '_call_fn_arg_defaults',\n",
       " '_call_fn_arg_positions',\n",
       " '_call_fn_args',\n",
       " '_call_full_argspec',\n",
       " '_callable_losses',\n",
       " '_cast_single_input',\n",
       " '_channels_first',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_compute_causal_padding',\n",
       " '_compute_dtype',\n",
       " '_compute_dtype_object',\n",
       " '_convolution_op',\n",
       " '_dedup_weights',\n",
       " '_default_training_arg',\n",
       " '_deferred_dependencies',\n",
       " '_dtype',\n",
       " '_dtype_policy',\n",
       " '_dynamic',\n",
       " '_eager_losses',\n",
       " '_expects_mask_arg',\n",
       " '_expects_training_arg',\n",
       " '_flatten',\n",
       " '_flatten_layers',\n",
       " '_functional_construction_call',\n",
       " '_gather_children_attribute',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_call_arg_value',\n",
       " '_get_channel_axis',\n",
       " '_get_existing_metric',\n",
       " '_get_input_channel',\n",
       " '_get_input_masks',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_padding_op',\n",
       " '_get_save_spec',\n",
       " '_get_trainable_state',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_weight_regularization',\n",
       " '_inbound_nodes',\n",
       " '_inbound_nodes_value',\n",
       " '_infer_output_signature',\n",
       " '_init_call_fn_args',\n",
       " '_init_set_name',\n",
       " '_initial_weights',\n",
       " '_input_spec',\n",
       " '_instrument_layer_creation',\n",
       " '_instrumented_keras_api',\n",
       " '_instrumented_keras_layer_class',\n",
       " '_instrumented_keras_model_class',\n",
       " '_is_causal',\n",
       " '_is_layer',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_keras_tensor_symbolic_call',\n",
       " '_layers',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_losses',\n",
       " '_map_resources',\n",
       " '_maybe_build',\n",
       " '_maybe_cast_inputs',\n",
       " '_maybe_create_attribute',\n",
       " '_maybe_initialize_trackable',\n",
       " '_metrics',\n",
       " '_metrics_lock',\n",
       " '_must_restore_from_config',\n",
       " '_name',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_no_dependency',\n",
       " '_non_trainable_weights',\n",
       " '_obj_reference_counts',\n",
       " '_obj_reference_counts_dict',\n",
       " '_object_identifier',\n",
       " '_outbound_nodes',\n",
       " '_outbound_nodes_value',\n",
       " '_preload_simple_restoration',\n",
       " '_preserve_input_structure_in_config',\n",
       " '_recreate_conv_op',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_saved_model_inputs_spec',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_set_call_arg_value',\n",
       " '_set_connectivity_metadata',\n",
       " '_set_dtype_policy',\n",
       " '_set_mask_keras_history_checked',\n",
       " '_set_mask_metadata',\n",
       " '_set_save_spec',\n",
       " '_set_trainable_state',\n",
       " '_set_training_mode',\n",
       " '_setattr_tracking',\n",
       " '_should_cast_single_input',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_spatial_output_shape',\n",
       " '_split_out_first_arg',\n",
       " '_stateful',\n",
       " '_supports_masking',\n",
       " '_symbolic_call',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_tf_data_format',\n",
       " '_thread_local',\n",
       " '_track_trackable',\n",
       " '_trackable_saved_model_saver',\n",
       " '_tracking_metadata',\n",
       " '_trainable',\n",
       " '_trainable_weights',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_updates',\n",
       " '_validate_init',\n",
       " 'activation',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'apply',\n",
       " 'bias',\n",
       " 'bias_constraint',\n",
       " 'bias_initializer',\n",
       " 'bias_regularizer',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compute_dtype',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_signature',\n",
       " 'count_params',\n",
       " 'data_format',\n",
       " 'dilation_rate',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'dynamic',\n",
       " 'filters',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'groups',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'kernel',\n",
       " 'kernel_constraint',\n",
       " 'kernel_initializer',\n",
       " 'kernel_regularizer',\n",
       " 'kernel_size',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'name',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_shape',\n",
       " 'padding',\n",
       " 'rank',\n",
       " 'set_weights',\n",
       " 'stateful',\n",
       " 'strides',\n",
       " 'submodules',\n",
       " 'supports_masking',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'use_bias',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights',\n",
       " 'with_name_scope']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.activations.softmax(x, axis=-1)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-1].activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def lrp(model, x, y):\n",
    "    Rn = model.layers[-1].activation(y)\n",
    "    Rnp1 = 0\n",
    "    # Compute activations\n",
    "    A = []\n",
    "    xi = x\n",
    "    for L in model.layers:\n",
    "        print(L)\n",
    "        xi = L.apply(xi)\n",
    "        if isinstance(L, tf.keras.layers.InputLayer):\n",
    "            A.append(xi)\n",
    "        else:\n",
    "            A.append(L.activation(xi))\n",
    "    \n",
    "    i = len(model.layers)\n",
    "    for L in model.layers[:1:-1]:\n",
    "        z = np.eps + A[i].dot(L.weights)\n",
    "        s = Rn / z\n",
    "        c = s.dot(L.weights)\n",
    "        Rn = A[i - 1] * c\n",
    "        i = i - 1\n",
    "    \n",
    "    return Rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6849224ae25d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlrp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xs' is not defined"
     ]
    }
   ],
   "source": [
    "lrp(model, xs[0], ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[159.,  27.,  38.],\n",
       "         [157.,  25.,  38.],\n",
       "         [161.,  29.,  37.],\n",
       "         ...,\n",
       "         [161.,  29.,  37.],\n",
       "         [161.,  29.,  37.],\n",
       "         [157.,  25.,  38.]],\n",
       "\n",
       "        [[190.,  82.,  54.],\n",
       "         [189.,  80.,  52.],\n",
       "         [190.,  82.,  54.],\n",
       "         ...,\n",
       "         [191.,  87.,  58.],\n",
       "         [192.,  90.,  60.],\n",
       "         [191.,  87.,  58.]],\n",
       "\n",
       "        [[ 81.,  13.,  28.],\n",
       "         [ 60.,   9.,  18.],\n",
       "         [ 70.,  11.,  23.],\n",
       "         ...,\n",
       "         [155.,  23.,  39.],\n",
       "         [ 60.,   9.,  18.],\n",
       "         [118.,  14.,  40.]]],\n",
       "\n",
       "\n",
       "       [[[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[185.,  69.,  44.],\n",
       "         [188.,  77.,  50.],\n",
       "         [190.,  85.,  56.],\n",
       "         ...,\n",
       "         [191.,  87.,  58.],\n",
       "         [188.,  77.,  50.],\n",
       "         [184.,  67.,  43.]],\n",
       "\n",
       "        [[201., 116.,  88.],\n",
       "         [202., 121.,  93.],\n",
       "         [202., 121.,  93.],\n",
       "         ...,\n",
       "         [199., 109.,  80.],\n",
       "         [199., 109.,  80.],\n",
       "         [202., 118.,  91.]],\n",
       "\n",
       "        [[136.,  15.,  41.],\n",
       "         [209., 143., 121.],\n",
       "         [136.,  15.,  41.],\n",
       "         ...,\n",
       "         [171.,  41.,  36.],\n",
       "         [180.,  59.,  39.],\n",
       "         [202., 121.,  93.]]],\n",
       "\n",
       "\n",
       "       [[[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[165.,  33.,  37.],\n",
       "         [161.,  29.,  37.],\n",
       "         [163.,  31.,  37.],\n",
       "         ...,\n",
       "         [161.,  29.,  37.],\n",
       "         [161.,  29.,  37.],\n",
       "         [163.,  31.,  37.]],\n",
       "\n",
       "        [[185.,  69.,  44.],\n",
       "         [183.,  64.,  41.],\n",
       "         [186.,  72.,  46.],\n",
       "         ...,\n",
       "         [186.,  72.,  46.],\n",
       "         [186.,  72.,  46.],\n",
       "         [185.,  69.,  44.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [229., 206., 199.],\n",
       "         [229., 206., 199.],\n",
       "         [255., 255., 255.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[151.,  20.,  40.],\n",
       "         [153.,  22.,  39.],\n",
       "         [144.,  16.,  41.],\n",
       "         ...,\n",
       "         [153.,  22.,  39.],\n",
       "         [151.,  20.,  40.],\n",
       "         [151.,  20.,  40.]],\n",
       "\n",
       "        [[186.,  72.,  46.],\n",
       "         [184.,  67.,  43.],\n",
       "         [184.,  67.,  43.],\n",
       "         ...,\n",
       "         [183.,  64.,  41.],\n",
       "         [184.,  67.,  43.],\n",
       "         [186.,  72.,  46.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]]],\n",
       "\n",
       "\n",
       "       [[[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[187.,  75.,  48.],\n",
       "         [186.,  72.,  46.],\n",
       "         [188.,  77.,  50.],\n",
       "         ...,\n",
       "         [188.,  77.,  50.],\n",
       "         [188.,  77.,  50.],\n",
       "         [188.,  77.,  50.]],\n",
       "\n",
       "        [[191.,  87.,  58.],\n",
       "         [191.,  87.,  58.],\n",
       "         [192.,  90.,  60.],\n",
       "         ...,\n",
       "         [193.,  92.,  63.],\n",
       "         [192.,  90.,  60.],\n",
       "         [192.,  90.,  60.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]]],\n",
       "\n",
       "\n",
       "       [[[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[211., 148., 127.],\n",
       "         [209., 143., 121.],\n",
       "         [209., 143., 121.],\n",
       "         ...,\n",
       "         [206., 132., 107.],\n",
       "         [207., 134., 110.],\n",
       "         [206., 132., 107.]],\n",
       "\n",
       "        [[220., 180., 167.],\n",
       "         [220., 178., 164.],\n",
       "         [220., 180., 167.],\n",
       "         ...,\n",
       "         [217., 169., 152.],\n",
       "         [216., 166., 150.],\n",
       "         [216., 164., 147.]],\n",
       "\n",
       "        [[224., 192., 181.],\n",
       "         [224., 192., 181.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.argmax(np.concatenate([labels_predict]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.zeros_like(classes)\n",
    "i = 0\n",
    "while i < len(classes):\n",
    "    if i < labels_predict.shape[0]:\n",
    "        x, y = valid_generator.next()\n",
    "    else:\n",
    "        x, y = train_generator.next()\n",
    "    y_true[i:i+y.shape[0]] = np.argmax(y, axis=1)\n",
    "    i += y.shape[0]\n",
    "con_mat = tf.math.confusion_matrix(labels=y_true, predictions=classes).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdf282e5dd0>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.argmax(labels_predict, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.matshow(con_mat, cmap='Reds')\n",
    "for (i, j), z in np.ndenumerate(con_mat):\n",
    "    ax.text(j, i, '{:d}'.format(z), ha='center', va='center', color='k', fontsize=16)\n",
    "\n",
    "ax.set_xticks([0, 1, 2])\n",
    "ax.set_yticks([0, 1, 2])\n",
    "ax.set_xticklabels(['Clear', 'Cloudy', 'Rain'])\n",
    "ax.set_yticklabels(['Clear', 'Cloudy', 'Rain'])\n",
    "ax.set_xlabel('Hand label')\n",
    "ax.set_ylabel('Predicted label')\n",
    "fig.savefig('confusion_matrix_1layer_vgg19_oversample.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11132 images belonging to 3 classes.\n",
      "Found 2922 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/training',\n",
    "                                                    class_mode='input', target_size=(1024, 128), shuffle=True,\n",
    "                                                    batch_size=16)\n",
    "valid_generator = train_datagen.flow_from_directory(directory='/lambda_stor/data/rjackson/lidar_pngs/5min/validation',\n",
    "                                                    class_mode='input', \n",
    "                                                    target_size=(1024, 128), shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net_encoder():\n",
    "    ref_inp = Input(shape=(1024, 128, 3), name='snr')\n",
    "      \n",
    "    x = Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(ref_inp)\n",
    "    l1 = Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_normal',  padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l1)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    l2 = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal',  padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l2)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(16, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    l3 = Conv2D(16, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l3)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(8, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    l4 = Conv2D(8, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l4)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(4, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    l5 = Conv2D(4, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l5)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(2, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    l6 = Conv2D(2, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(l6)\n",
    "    encode = MaxPooling2D((2,2), name='encoding')(x)\n",
    "    \n",
    "    x = Conv2DTranspose(2, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(encode)\n",
    "    x = Conv2DTranspose(2, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2DTranspose(4, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = Conv2DTranspose(4, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2DTranspose(8, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = Conv2DTranspose(8, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2DTranspose(16, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = Conv2DTranspose(16, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    ref_out = Conv2DTranspose(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(x)\n",
    "    ref_out = Conv2DTranspose(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(ref_out)\n",
    "    ref_out = BatchNormalization()(ref_out)\n",
    "    ref_out = UpSampling2D((2,2))(ref_out)\n",
    "    ref_out = Conv2DTranspose(64, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(ref_out)\n",
    "    ref_out = Conv2DTranspose(64, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(ref_out)\n",
    "    ref_out = BatchNormalization()(ref_out)\n",
    "    ref_out = UpSampling2D((2,2))(ref_out)\n",
    "    ref_out = Conv2DTranspose(3, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same', activation='relu')(ref_out)\n",
    "    return Model(ref_inp, ref_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = conv_net_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "snr (InputLayer)             [(None, 1024, 128, 3)]    0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 1024, 128, 64)     1792      \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 1024, 128, 64)     36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 1024, 128, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 512, 64, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 512, 64, 32)       18464     \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 512, 64, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 512, 64, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 256, 32, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 256, 32, 16)       4624      \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 256, 32, 16)       2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 256, 32, 16)       64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 128, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 128, 16, 8)        1160      \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 128, 16, 8)        584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 128, 16, 8)        32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 64, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 64, 8, 4)          292       \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 64, 8, 4)          148       \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 64, 8, 4)          16        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 32, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 32, 4, 2)          74        \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 32, 4, 2)          38        \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 32, 4, 2)          8         \n",
      "_________________________________________________________________\n",
      "encoding (MaxPooling2D)      (None, 16, 2, 2)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_48 (Conv2DT (None, 16, 2, 2)          38        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_49 (Conv2DT (None, 16, 2, 2)          38        \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 16, 2, 2)          8         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling (None, 32, 4, 2)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_50 (Conv2DT (None, 32, 4, 4)          76        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_51 (Conv2DT (None, 32, 4, 4)          148       \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 32, 4, 4)          16        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling (None, 64, 8, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_52 (Conv2DT (None, 64, 8, 8)          296       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_53 (Conv2DT (None, 64, 8, 8)          584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 64, 8, 8)          32        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling (None, 128, 16, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_54 (Conv2DT (None, 128, 16, 16)       1168      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_55 (Conv2DT (None, 128, 16, 16)       2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 128, 16, 16)       64        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_25 (UpSampling (None, 256, 32, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_56 (Conv2DT (None, 256, 32, 32)       4640      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_57 (Conv2DT (None, 256, 32, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 256, 32, 32)       128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_26 (UpSampling (None, 512, 64, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_58 (Conv2DT (None, 512, 64, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_59 (Conv2DT (None, 512, 64, 64)       36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 512, 64, 64)       256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_27 (UpSampling (None, 1024, 128, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_60 (Conv2DT (None, 1024, 128, 3)      1731      \n",
      "=================================================================\n",
      "Total params: 152,391\n",
      "Trainable params: 151,887\n",
      "Non-trainable params: 504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "696/696 [==============================] - 127s 180ms/step - loss: 0.3905 - val_loss: 0.0148\n",
      "\n",
      "Epoch 00001: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-001.hdf5\n",
      "Epoch 2/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00002: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-002.hdf5\n",
      "Epoch 3/150\n",
      "696/696 [==============================] - 124s 179ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "\n",
      "Epoch 00003: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-003.hdf5\n",
      "Epoch 4/150\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 0.0068 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00004: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-004.hdf5\n",
      "Epoch 5/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00005: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-005.hdf5\n",
      "Epoch 6/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00006: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-006.hdf5\n",
      "Epoch 7/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "\n",
      "Epoch 00007: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-007.hdf5\n",
      "Epoch 8/150\n",
      "696/696 [==============================] - 127s 183ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "\n",
      "Epoch 00008: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-008.hdf5\n",
      "Epoch 9/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0011 - val_loss: 8.8905e-04\n",
      "\n",
      "Epoch 00009: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-009.hdf5\n",
      "Epoch 10/150\n",
      "696/696 [==============================] - 128s 183ms/step - loss: 0.0015 - val_loss: 8.8172e-04\n",
      "\n",
      "Epoch 00010: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-010.hdf5\n",
      "Epoch 11/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0014 - val_loss: 6.3344e-04\n",
      "\n",
      "Epoch 00011: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-011.hdf5\n",
      "Epoch 12/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "\n",
      "Epoch 00012: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-012.hdf5\n",
      "Epoch 13/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0016 - val_loss: 8.7753e-04\n",
      "\n",
      "Epoch 00013: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-013.hdf5\n",
      "Epoch 14/150\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 0.0010 - val_loss: 7.7545e-04\n",
      "\n",
      "Epoch 00014: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-014.hdf5\n",
      "Epoch 15/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 9.5329e-04 - val_loss: 8.7721e-04\n",
      "\n",
      "Epoch 00015: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-015.hdf5\n",
      "Epoch 16/150\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 0.0011 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00016: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-016.hdf5\n",
      "Epoch 17/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "\n",
      "Epoch 00017: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-017.hdf5\n",
      "Epoch 18/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0010 - val_loss: 9.5924e-04\n",
      "\n",
      "Epoch 00018: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-018.hdf5\n",
      "Epoch 19/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0017 - val_loss: 8.2644e-04\n",
      "\n",
      "Epoch 00019: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-019.hdf5\n",
      "Epoch 20/150\n",
      "696/696 [==============================] - 126s 180ms/step - loss: 8.0142e-04 - val_loss: 7.8019e-04\n",
      "\n",
      "Epoch 00020: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-020.hdf5\n",
      "Epoch 21/150\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 7.4043e-04 - val_loss: 7.7402e-04\n",
      "\n",
      "Epoch 00021: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-021.hdf5\n",
      "Epoch 22/150\n",
      "696/696 [==============================] - 124s 179ms/step - loss: 7.4143e-04 - val_loss: 7.4148e-04\n",
      "\n",
      "Epoch 00022: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-022.hdf5\n",
      "Epoch 23/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 6.9828e-04 - val_loss: 6.7765e-04\n",
      "\n",
      "Epoch 00023: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-023.hdf5\n",
      "Epoch 24/150\n",
      "696/696 [==============================] - 123s 176ms/step - loss: 6.5932e-04 - val_loss: 6.5417e-04\n",
      "\n",
      "Epoch 00024: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-024.hdf5\n",
      "Epoch 25/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 7.1212e-04 - val_loss: 6.5385e-04\n",
      "\n",
      "Epoch 00025: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-025.hdf5\n",
      "Epoch 26/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00026: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-026.hdf5\n",
      "Epoch 27/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 7.0270e-04 - val_loss: 5.8310e-04\n",
      "\n",
      "Epoch 00027: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-027.hdf5\n",
      "Epoch 28/150\n",
      "696/696 [==============================] - 123s 177ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00028: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-028.hdf5\n",
      "Epoch 29/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00029: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-029.hdf5\n",
      "Epoch 30/150\n",
      "696/696 [==============================] - 123s 177ms/step - loss: 9.0525e-04 - val_loss: 7.4587e-04\n",
      "\n",
      "Epoch 00030: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-030.hdf5\n",
      "Epoch 31/150\n",
      "696/696 [==============================] - 124s 177ms/step - loss: 8.5614e-04 - val_loss: 6.6528e-04\n",
      "\n",
      "Epoch 00031: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-031.hdf5\n",
      "Epoch 32/150\n",
      "696/696 [==============================] - 123s 177ms/step - loss: 7.5662e-04 - val_loss: 6.4786e-04\n",
      "\n",
      "Epoch 00032: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-032.hdf5\n",
      "Epoch 33/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 6.8877e-04 - val_loss: 6.3346e-04\n",
      "\n",
      "Epoch 00033: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-033.hdf5\n",
      "Epoch 34/150\n",
      "696/696 [==============================] - 124s 179ms/step - loss: 6.5213e-04 - val_loss: 5.9801e-04\n",
      "\n",
      "Epoch 00034: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-034.hdf5\n",
      "Epoch 35/150\n",
      "696/696 [==============================] - 124s 179ms/step - loss: 6.1240e-04 - val_loss: 5.4017e-04\n",
      "\n",
      "Epoch 00035: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-035.hdf5\n",
      "Epoch 36/150\n",
      "696/696 [==============================] - 126s 180ms/step - loss: 0.0098 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00036: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-036.hdf5\n",
      "Epoch 37/150\n",
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00037: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-037.hdf5\n",
      "Epoch 38/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 0.0011 - val_loss: 9.4122e-04\n",
      "\n",
      "Epoch 00038: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-038.hdf5\n",
      "Epoch 39/150\n",
      "696/696 [==============================] - 123s 177ms/step - loss: 8.3711e-04 - val_loss: 7.4356e-04\n",
      "\n",
      "Epoch 00039: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-039.hdf5\n",
      "Epoch 40/150\n",
      "696/696 [==============================] - 124s 178ms/step - loss: 7.5907e-04 - val_loss: 6.3069e-04\n",
      "\n",
      "Epoch 00040: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-040.hdf5\n",
      "Epoch 41/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 126s 181ms/step - loss: 0.0014 - val_loss: 8.9630e-04\n",
      "\n",
      "Epoch 00041: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-041.hdf5\n",
      "Epoch 42/150\n",
      "696/696 [==============================] - 125s 179ms/step - loss: 0.0028 - val_loss: 9.3771e-04\n",
      "\n",
      "Epoch 00042: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-042.hdf5\n",
      "Epoch 43/150\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 0.0014 - val_loss: 8.7103e-04\n",
      "\n",
      "Epoch 00043: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-043.hdf5\n",
      "Epoch 44/150\n",
      "696/696 [==============================] - 127s 183ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "\n",
      "Epoch 00044: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-044.hdf5\n",
      "Epoch 45/150\n",
      "696/696 [==============================] - 169s 243ms/step - loss: 0.0012 - val_loss: 8.7371e-04\n",
      "\n",
      "Epoch 00045: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-045.hdf5\n",
      "Epoch 46/150\n",
      "696/696 [==============================] - 171s 245ms/step - loss: 0.0012 - val_loss: 9.1495e-04\n",
      "\n",
      "Epoch 00046: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-046.hdf5\n",
      "Epoch 47/150\n",
      "696/696 [==============================] - 166s 239ms/step - loss: 8.7242e-04 - val_loss: 7.9038e-04\n",
      "\n",
      "Epoch 00047: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-047.hdf5\n",
      "Epoch 48/150\n",
      "696/696 [==============================] - 151s 216ms/step - loss: 7.5800e-04 - val_loss: 7.3487e-04\n",
      "\n",
      "Epoch 00048: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-048.hdf5\n",
      "Epoch 49/150\n",
      "696/696 [==============================] - 151s 217ms/step - loss: 6.9002e-04 - val_loss: 6.2775e-04\n",
      "\n",
      "Epoch 00049: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-049.hdf5\n",
      "Epoch 50/150\n",
      "696/696 [==============================] - 163s 234ms/step - loss: 6.2795e-04 - val_loss: 5.9497e-04\n",
      "\n",
      "Epoch 00050: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-050.hdf5\n",
      "Epoch 51/150\n",
      "696/696 [==============================] - 175s 252ms/step - loss: 5.8960e-04 - val_loss: 7.6070e-04\n",
      "\n",
      "Epoch 00051: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-051.hdf5\n",
      "Epoch 52/150\n",
      "696/696 [==============================] - 170s 244ms/step - loss: 6.1853e-04 - val_loss: 5.3217e-04\n",
      "\n",
      "Epoch 00052: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-052.hdf5\n",
      "Epoch 53/150\n",
      "696/696 [==============================] - 165s 237ms/step - loss: 5.4616e-04 - val_loss: 0.0032\n",
      "\n",
      "Epoch 00053: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-053.hdf5\n",
      "Epoch 54/150\n",
      "696/696 [==============================] - 198s 284ms/step - loss: 5.3067e-04 - val_loss: 8.5383e-04\n",
      "\n",
      "Epoch 00054: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-054.hdf5\n",
      "Epoch 55/150\n",
      "696/696 [==============================] - 193s 276ms/step - loss: 5.0544e-04 - val_loss: 5.1993e-04\n",
      "\n",
      "Epoch 00055: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-055.hdf5\n",
      "Epoch 56/150\n",
      "696/696 [==============================] - 200s 287ms/step - loss: 6.0645e-04 - val_loss: 9.1033e-04\n",
      "\n",
      "Epoch 00056: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-056.hdf5\n",
      "Epoch 57/150\n",
      "696/696 [==============================] - 196s 282ms/step - loss: 7.4951e-04 - val_loss: 6.4972e-04\n",
      "\n",
      "Epoch 00057: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-057.hdf5\n",
      "Epoch 58/150\n",
      "696/696 [==============================] - 212s 305ms/step - loss: 6.3638e-04 - val_loss: 8.0937e-04\n",
      "\n",
      "Epoch 00058: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-058.hdf5\n",
      "Epoch 59/150\n",
      "696/696 [==============================] - 199s 285ms/step - loss: 8.4710e-04 - val_loss: 7.2502e-04\n",
      "\n",
      "Epoch 00059: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-059.hdf5\n",
      "Epoch 60/150\n",
      "696/696 [==============================] - 212s 304ms/step - loss: 7.6069e-04 - val_loss: 7.8583e-04\n",
      "\n",
      "Epoch 00060: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-060.hdf5\n",
      "Epoch 61/150\n",
      "696/696 [==============================] - 202s 289ms/step - loss: 8.5975e-04 - val_loss: 9.7566e-04\n",
      "\n",
      "Epoch 00061: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-061.hdf5\n",
      "Epoch 62/150\n",
      "696/696 [==============================] - 190s 273ms/step - loss: 0.0013 - val_loss: 7.9373e-04\n",
      "\n",
      "Epoch 00062: saving model to /homes/rjackson/arming_the_edge/models/encoder-%dframes-062.hdf5\n",
      "Epoch 63/150\n",
      "236/696 [=========>....................] - ETA: 1:38 - loss: 0.0013"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e6f1964aa9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/homes/rjackson/arming_the_edge/models/encoder-%dframes-{epoch:03d}.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                verbose=1)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "               filepath=('/homes/rjackson/arming_the_edge/models/encoder-%dframes-{epoch:03d}.hdf5'),\n",
    "               verbose=1)\n",
    "autoencoder.fit(train_generator, validation_data=valid_generator, epochs=150, callbacks=[checkpointer], initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: /homes/rjackson/arming_the_edge/models/encoder-%dframes-055.hdf5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2b0d9230b1fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/homes/rjackson/arming_the_edge/models/encoder-%dframes-055.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   raise IOError(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 116\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /homes/rjackson/arming_the_edge/models/encoder-%dframes-055.hdf5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "encoder = load_model('/homes/rjackson/arming_the_edge/models/encoder-%dframes-055.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:5'):\n",
    "    pics = autoencoder.predict(train_generator.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(autoencoder.input, autoencoder.get_layer('encoding').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:6'):\n",
    "    encodings = encoder.predict(train_generator)\n",
    "    encodings_validation = encoder.predict(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = np.reshape(encodings, (encodings.shape[0], encodings.shape[1]*encodings.shape[2]*encodings.shape[3]))\n",
    "encodings_validation = np.reshape(encodings_validation, \n",
    "                                  (encodings_validation.shape[0],\n",
    "                                   encodings_validation.shape[1]*encodings_validation.shape[2]*encodings_validation.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_validation = np.reshape(encodings_validation, \n",
    "                                  (encodings_validation.shape[0],\n",
    "                                   encodings_validation.shape[1]*encodings_validation.shape[2]*encodings_validation.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_valid = np.squeeze(np.argwhere(np.isfinite(np.sum(encodings, axis=1))))\n",
    "encodings = encodings[encodings_valid, :]\n",
    "encodings_valid = np.squeeze(np.argwhere(np.isfinite(np.sum(encodings_validation, axis=1))))\n",
    "encodings_validation = encodings_validation[encodings_valid, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11132, 64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.zeros((encodings.shape[0], 3))\n",
    "valid_labels = np.zeros((encodings_validation.shape[0], 3))\n",
    "\n",
    "for i in range(0, encodings.shape[0], 16):\n",
    "    x, y = train_generator.next()\n",
    "    num_y = y.shape[0]\n",
    "    train_labels[i:i+num_y, :] = y[:num_y, :]\n",
    "    \n",
    "for i in range(0, encodings_validation.shape[0], 16):\n",
    "    x, y = valid_generator.next()\n",
    "    num_y = y.shape[0]\n",
    "    valid_labels[i:i+num_y, :] = y[:num_y, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_encodings():\n",
    "    ref_inp = Input(shape=(64,), name='snr')\n",
    "    x = ref_inp\n",
    "    for i in range(10):\n",
    "        x = Dense(2048, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "    out = Dense(3, activation='softmax')(x)\n",
    "    return Model(ref_inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "snr (InputLayer)             [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 2048)              133120    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 3)                 6147      \n",
      "=================================================================\n",
      "Total params: 37,906,435\n",
      "Trainable params: 37,906,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_classifier = nn_encodings()\n",
    "nn_classifier.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "nn_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "348/348 [==============================] - 3s 6ms/step - loss: 0.8497 - accuracy: 0.6895 - val_loss: 0.7815 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00001: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-001.hdf5\n",
      "Epoch 2/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7863 - accuracy: 0.6997 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00002: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-002.hdf5\n",
      "Epoch 3/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7711 - accuracy: 0.7078 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00003: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-003.hdf5\n",
      "Epoch 4/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7740 - accuracy: 0.6999 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00004: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-004.hdf5\n",
      "Epoch 5/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7842 - accuracy: 0.6948 - val_loss: 0.7917 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00005: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-005.hdf5\n",
      "Epoch 6/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7677 - accuracy: 0.7079 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00006: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-006.hdf5\n",
      "Epoch 7/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7697 - accuracy: 0.7066 - val_loss: 0.7802 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00007: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-007.hdf5\n",
      "Epoch 8/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7729 - accuracy: 0.7038 - val_loss: 0.7807 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00008: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-008.hdf5\n",
      "Epoch 9/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7600 - accuracy: 0.7091 - val_loss: 0.7827 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00009: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-009.hdf5\n",
      "Epoch 10/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7805 - accuracy: 0.7015 - val_loss: 0.7850 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00010: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-010.hdf5\n",
      "Epoch 11/150\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 0.7725 - accuracy: 0.7039 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00011: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-011.hdf5\n",
      "Epoch 12/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7595 - accuracy: 0.7094 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00012: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-012.hdf5\n",
      "Epoch 13/150\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 0.7745 - accuracy: 0.7008 - val_loss: 0.7829 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00013: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-013.hdf5\n",
      "Epoch 14/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7567 - accuracy: 0.7118 - val_loss: 0.7815 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00014: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-014.hdf5\n",
      "Epoch 15/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7774 - accuracy: 0.6979 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00015: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-015.hdf5\n",
      "Epoch 16/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7688 - accuracy: 0.7029 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00016: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-016.hdf5\n",
      "Epoch 17/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7738 - accuracy: 0.6994 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00017: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-017.hdf5\n",
      "Epoch 18/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7749 - accuracy: 0.6993 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00018: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-018.hdf5\n",
      "Epoch 19/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7624 - accuracy: 0.7098 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00019: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-019.hdf5\n",
      "Epoch 20/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7703 - accuracy: 0.7034 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00020: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-020.hdf5\n",
      "Epoch 21/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7701 - accuracy: 0.7023 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00021: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-021.hdf5\n",
      "Epoch 22/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7801 - accuracy: 0.6997 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00022: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-022.hdf5\n",
      "Epoch 23/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7745 - accuracy: 0.7005 - val_loss: 0.7804 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00023: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-023.hdf5\n",
      "Epoch 24/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7773 - accuracy: 0.6973 - val_loss: 0.7805 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00024: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-024.hdf5\n",
      "Epoch 25/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7746 - accuracy: 0.7031 - val_loss: 0.7830 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00025: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-025.hdf5\n",
      "Epoch 26/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7690 - accuracy: 0.7073 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00026: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-026.hdf5\n",
      "Epoch 27/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7649 - accuracy: 0.7075 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00027: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-027.hdf5\n",
      "Epoch 28/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7658 - accuracy: 0.7057 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00028: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-028.hdf5\n",
      "Epoch 29/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7789 - accuracy: 0.6999 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00029: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-029.hdf5\n",
      "Epoch 30/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7836 - accuracy: 0.6967 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00030: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-030.hdf5\n",
      "Epoch 31/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7635 - accuracy: 0.7066 - val_loss: 0.7802 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00031: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-031.hdf5\n",
      "Epoch 32/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7707 - accuracy: 0.7016 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00032: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-032.hdf5\n",
      "Epoch 33/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7686 - accuracy: 0.7040 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00033: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-033.hdf5\n",
      "Epoch 34/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7678 - accuracy: 0.7049 - val_loss: 0.7805 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00034: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-034.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7763 - accuracy: 0.7030 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00035: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-035.hdf5\n",
      "Epoch 36/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7678 - accuracy: 0.7024 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00036: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-036.hdf5\n",
      "Epoch 37/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7650 - accuracy: 0.7048 - val_loss: 0.7818 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00037: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-037.hdf5\n",
      "Epoch 38/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7602 - accuracy: 0.7092 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00038: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-038.hdf5\n",
      "Epoch 39/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7620 - accuracy: 0.7093 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00039: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-039.hdf5\n",
      "Epoch 40/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7894 - accuracy: 0.6931 - val_loss: 0.7801 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00040: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-040.hdf5\n",
      "Epoch 41/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7687 - accuracy: 0.7052 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00041: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-041.hdf5\n",
      "Epoch 42/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7694 - accuracy: 0.7043 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00042: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-042.hdf5\n",
      "Epoch 43/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7828 - accuracy: 0.6954 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00043: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-043.hdf5\n",
      "Epoch 44/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7632 - accuracy: 0.7101 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00044: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-044.hdf5\n",
      "Epoch 45/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7599 - accuracy: 0.7067 - val_loss: 0.7805 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00045: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-045.hdf5\n",
      "Epoch 46/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7627 - accuracy: 0.7060 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00046: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-046.hdf5\n",
      "Epoch 47/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7742 - accuracy: 0.7018 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00047: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-047.hdf5\n",
      "Epoch 48/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7623 - accuracy: 0.7066 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00048: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-048.hdf5\n",
      "Epoch 49/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7611 - accuracy: 0.7083 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00049: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-049.hdf5\n",
      "Epoch 50/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7856 - accuracy: 0.6940 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00050: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-050.hdf5\n",
      "Epoch 51/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7760 - accuracy: 0.6992 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00051: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-051.hdf5\n",
      "Epoch 52/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7714 - accuracy: 0.7011 - val_loss: 0.7815 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00052: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-052.hdf5\n",
      "Epoch 53/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7603 - accuracy: 0.7107 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00053: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-053.hdf5\n",
      "Epoch 54/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7618 - accuracy: 0.7104 - val_loss: 0.7801 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00054: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-054.hdf5\n",
      "Epoch 55/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7789 - accuracy: 0.6980 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00055: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-055.hdf5\n",
      "Epoch 56/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7535 - accuracy: 0.7152 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00056: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-056.hdf5\n",
      "Epoch 57/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7620 - accuracy: 0.7063 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00057: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-057.hdf5\n",
      "Epoch 58/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7617 - accuracy: 0.7063 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00058: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-058.hdf5\n",
      "Epoch 59/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7689 - accuracy: 0.7040 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00059: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-059.hdf5\n",
      "Epoch 60/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7709 - accuracy: 0.7054 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00060: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-060.hdf5\n",
      "Epoch 61/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7754 - accuracy: 0.6975 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00061: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-061.hdf5\n",
      "Epoch 62/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7680 - accuracy: 0.7053 - val_loss: 0.7801 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00062: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-062.hdf5\n",
      "Epoch 63/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7768 - accuracy: 0.6974 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00063: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-063.hdf5\n",
      "Epoch 64/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7765 - accuracy: 0.6987 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00064: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-064.hdf5\n",
      "Epoch 65/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7733 - accuracy: 0.7016 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00065: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-065.hdf5\n",
      "Epoch 66/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7723 - accuracy: 0.7041 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00066: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-066.hdf5\n",
      "Epoch 67/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7667 - accuracy: 0.7044 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00067: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-067.hdf5\n",
      "Epoch 68/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7643 - accuracy: 0.7065 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00068: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-068.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7630 - accuracy: 0.7115 - val_loss: 0.7812 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00069: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-069.hdf5\n",
      "Epoch 70/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7709 - accuracy: 0.7034 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00070: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-070.hdf5\n",
      "Epoch 71/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7661 - accuracy: 0.7057 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00071: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-071.hdf5\n",
      "Epoch 72/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7678 - accuracy: 0.7047 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00072: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-072.hdf5\n",
      "Epoch 73/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7674 - accuracy: 0.7053 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00073: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-073.hdf5\n",
      "Epoch 74/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7756 - accuracy: 0.7009 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00074: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-074.hdf5\n",
      "Epoch 75/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7761 - accuracy: 0.6990 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00075: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-075.hdf5\n",
      "Epoch 76/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7727 - accuracy: 0.7021 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00076: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-076.hdf5\n",
      "Epoch 77/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7705 - accuracy: 0.7008 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00077: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-077.hdf5\n",
      "Epoch 78/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7653 - accuracy: 0.7034 - val_loss: 0.7801 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00078: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-078.hdf5\n",
      "Epoch 79/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7733 - accuracy: 0.6987 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00079: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-079.hdf5\n",
      "Epoch 80/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7526 - accuracy: 0.7165 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00080: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-080.hdf5\n",
      "Epoch 81/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7754 - accuracy: 0.6968 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00081: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-081.hdf5\n",
      "Epoch 82/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7741 - accuracy: 0.6976 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00082: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-082.hdf5\n",
      "Epoch 83/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7632 - accuracy: 0.7066 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00083: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-083.hdf5\n",
      "Epoch 84/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7729 - accuracy: 0.7001 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00084: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-084.hdf5\n",
      "Epoch 85/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7626 - accuracy: 0.7070 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00085: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-085.hdf5\n",
      "Epoch 86/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7729 - accuracy: 0.7000 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00086: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-086.hdf5\n",
      "Epoch 87/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7819 - accuracy: 0.6953 - val_loss: 0.7803 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00087: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-087.hdf5\n",
      "Epoch 88/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7611 - accuracy: 0.7082 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00088: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-088.hdf5\n",
      "Epoch 89/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7733 - accuracy: 0.6985 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00089: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-089.hdf5\n",
      "Epoch 90/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7699 - accuracy: 0.7054 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00090: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-090.hdf5\n",
      "Epoch 91/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7703 - accuracy: 0.7058 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00091: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-091.hdf5\n",
      "Epoch 92/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7678 - accuracy: 0.7008 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00092: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-092.hdf5\n",
      "Epoch 93/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7637 - accuracy: 0.7028 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00093: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-093.hdf5\n",
      "Epoch 94/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7697 - accuracy: 0.7018 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00094: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-094.hdf5\n",
      "Epoch 95/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7659 - accuracy: 0.7047 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00095: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-095.hdf5\n",
      "Epoch 96/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7588 - accuracy: 0.7094 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00096: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-096.hdf5\n",
      "Epoch 97/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7619 - accuracy: 0.7064 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00097: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-097.hdf5\n",
      "Epoch 98/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7593 - accuracy: 0.7087 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00098: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-098.hdf5\n",
      "Epoch 99/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7630 - accuracy: 0.7048 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00099: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-099.hdf5\n",
      "Epoch 100/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7711 - accuracy: 0.7046 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00100: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-100.hdf5\n",
      "Epoch 101/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7643 - accuracy: 0.7062 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00101: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-101.hdf5\n",
      "Epoch 102/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7591 - accuracy: 0.7080 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00102: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-102.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7623 - accuracy: 0.7082 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00103: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-103.hdf5\n",
      "Epoch 104/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7674 - accuracy: 0.7041 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00104: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-104.hdf5\n",
      "Epoch 105/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7723 - accuracy: 0.7022 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00105: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-105.hdf5\n",
      "Epoch 106/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7647 - accuracy: 0.7044 - val_loss: 0.7800 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00106: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-106.hdf5\n",
      "Epoch 107/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7715 - accuracy: 0.7063 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00107: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-107.hdf5\n",
      "Epoch 108/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7751 - accuracy: 0.7039 - val_loss: 0.7798 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00108: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-108.hdf5\n",
      "Epoch 109/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7700 - accuracy: 0.7044 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00109: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-109.hdf5\n",
      "Epoch 110/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7638 - accuracy: 0.7068 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00110: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-110.hdf5\n",
      "Epoch 111/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7695 - accuracy: 0.7037 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00111: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-111.hdf5\n",
      "Epoch 112/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7801 - accuracy: 0.6958 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00112: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-112.hdf5\n",
      "Epoch 113/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7820 - accuracy: 0.6936 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00113: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-113.hdf5\n",
      "Epoch 114/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7739 - accuracy: 0.6967 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00114: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-114.hdf5\n",
      "Epoch 115/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7703 - accuracy: 0.7026 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00115: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-115.hdf5\n",
      "Epoch 116/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7673 - accuracy: 0.7062 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00116: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-116.hdf5\n",
      "Epoch 117/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7667 - accuracy: 0.7031 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00117: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-117.hdf5\n",
      "Epoch 118/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7698 - accuracy: 0.7010 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00118: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-118.hdf5\n",
      "Epoch 119/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7622 - accuracy: 0.7083 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00119: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-119.hdf5\n",
      "Epoch 120/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7644 - accuracy: 0.7048 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00120: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-120.hdf5\n",
      "Epoch 121/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7832 - accuracy: 0.6936 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00121: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-121.hdf5\n",
      "Epoch 122/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7671 - accuracy: 0.7049 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00122: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-122.hdf5\n",
      "Epoch 123/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7785 - accuracy: 0.7019 - val_loss: 0.7799 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00123: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-123.hdf5\n",
      "Epoch 124/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7670 - accuracy: 0.7044 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00124: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-124.hdf5\n",
      "Epoch 125/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7701 - accuracy: 0.7002 - val_loss: 0.7795 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00125: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-125.hdf5\n",
      "Epoch 126/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7631 - accuracy: 0.7066 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00126: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-126.hdf5\n",
      "Epoch 127/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7627 - accuracy: 0.7029 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00127: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-127.hdf5\n",
      "Epoch 128/150\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 0.7689 - accuracy: 0.7027 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00128: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-128.hdf5\n",
      "Epoch 129/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7679 - accuracy: 0.7031 - val_loss: 0.7801 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00129: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-129.hdf5\n",
      "Epoch 130/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7749 - accuracy: 0.6994 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00130: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-130.hdf5\n",
      "Epoch 131/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7719 - accuracy: 0.7033 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00131: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-131.hdf5\n",
      "Epoch 132/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7782 - accuracy: 0.6963 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00132: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-132.hdf5\n",
      "Epoch 133/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7659 - accuracy: 0.7053 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00133: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-133.hdf5\n",
      "Epoch 134/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7727 - accuracy: 0.7011 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00134: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-134.hdf5\n",
      "Epoch 135/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7669 - accuracy: 0.7025 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00135: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-135.hdf5\n",
      "Epoch 136/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7580 - accuracy: 0.7066 - val_loss: 0.7793 - val_accuracy: 0.6968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00136: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-136.hdf5\n",
      "Epoch 137/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7690 - accuracy: 0.7042 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00137: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-137.hdf5\n",
      "Epoch 138/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7714 - accuracy: 0.7035 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00138: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-138.hdf5\n",
      "Epoch 139/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7670 - accuracy: 0.7047 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00139: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-139.hdf5\n",
      "Epoch 140/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7606 - accuracy: 0.7118 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00140: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-140.hdf5\n",
      "Epoch 141/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7605 - accuracy: 0.7087 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00141: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-141.hdf5\n",
      "Epoch 142/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7672 - accuracy: 0.7023 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00142: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-142.hdf5\n",
      "Epoch 143/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7625 - accuracy: 0.7085 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00143: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-143.hdf5\n",
      "Epoch 144/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7633 - accuracy: 0.7073 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00144: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-144.hdf5\n",
      "Epoch 145/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7686 - accuracy: 0.7048 - val_loss: 0.7793 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00145: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-145.hdf5\n",
      "Epoch 146/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7697 - accuracy: 0.7011 - val_loss: 0.7796 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00146: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-146.hdf5\n",
      "Epoch 147/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7616 - accuracy: 0.7062 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00147: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-147.hdf5\n",
      "Epoch 148/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7704 - accuracy: 0.7023 - val_loss: 0.7794 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00148: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-148.hdf5\n",
      "Epoch 149/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7619 - accuracy: 0.7059 - val_loss: 0.7792 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00149: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-149.hdf5\n",
      "Epoch 150/150\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.7795 - accuracy: 0.6977 - val_loss: 0.7797 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00150: saving model to /homes/rjackson/arming_the_edge/models/classifier-encodings-150.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b34f42cd0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "               filepath=('/homes/rjackson/arming_the_edge/models/classifier-encodings-{epoch:03d}.hdf5'),\n",
    "               verbose=1)\n",
    "nn_classifier.fit(encodings, train_labels, validation_data=(encodings_validation, valid_labels), epochs=150,\n",
    "                 callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "SSE = np.zeros(20)\n",
    "\n",
    "for i in range(1, 21):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(encodings)\n",
    "    SSE[i-1] = kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total squared error')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 21), SSE)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Total squared error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "kmeans = KMeans(n_clusters=num_classes)\n",
    "kmeans.fit(encodings)\n",
    "classes = kmeans.predict(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9843138 , 0.9843138 , 0.9843138 ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9843138 , 0.9843138 , 0.9843138 ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9450981 , 0.9450981 , 0.9450981 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9058824 , 0.9058824 , 0.9058824 ],\n",
       "          ...,\n",
       "          [0.9568628 , 0.9568628 , 0.9568628 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.90196085, 0.90196085, 0.90196085]],\n",
       " \n",
       "         [[0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.909804  , 0.909804  , 0.909804  ],\n",
       "          ...,\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.91372555, 0.91372555, 0.91372555]],\n",
       " \n",
       "         [[0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.909804  , 0.909804  , 0.909804  ],\n",
       "          ...,\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.91372555, 0.91372555, 0.91372555]]]], dtype=float32),\n",
       " array([[[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9843138 , 0.9843138 , 0.9843138 ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          [0.9803922 , 0.9803922 , 0.9803922 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9843138 , 0.9843138 , 0.9843138 ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9450981 , 0.9450981 , 0.9450981 ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.9058824 , 0.9058824 , 0.9058824 ],\n",
       "          ...,\n",
       "          [0.9568628 , 0.9568628 , 0.9568628 ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.90196085, 0.90196085, 0.90196085]],\n",
       " \n",
       "         [[0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.909804  , 0.909804  , 0.909804  ],\n",
       "          ...,\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.91372555, 0.91372555, 0.91372555]],\n",
       " \n",
       "         [[0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.909804  , 0.909804  , 0.909804  ],\n",
       "          ...,\n",
       "          [0.95294124, 0.95294124, 0.95294124],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [0.91372555, 0.91372555, 0.91372555]]]], dtype=float32))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x2160 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_class = 2\n",
    "where_class = np.argwhere(classes == my_class)\n",
    "fig, ax = plt.subplots(4, 4, figsize=(12,30))\n",
    "for i in range(16):\n",
    "    ax[int(i / 4), i % 4].imshow(np.squeeze(train_generator[int(where_class[i] / 16)][0][where_class[i] % 16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
